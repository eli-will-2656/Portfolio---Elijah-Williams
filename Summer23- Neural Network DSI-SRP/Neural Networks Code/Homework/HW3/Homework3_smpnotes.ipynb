{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Homework 3\n",
    "##\n",
    "## simple MNIST classifier network\n",
    "##\n",
    "## NSC3270/5270 Fall 2022\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# supress some unnecessary warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load, display, and format mnist images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# load mnist images\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "\n",
      "test\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# check dimensions and type of images and labels\n",
    "\n",
    "print('train')\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(type(train_images))\n",
    "print(type(train_labels))\n",
    "print()\n",
    "\n",
    "print('test')\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "print(type(test_images))\n",
    "print(type(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 60,000 train images and 10,000 test images. Each image is 28x28 pixels (gray scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the first 9 digits\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(train_images[i], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Digit: {}\".format(train_labels[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reformat training and testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape:  (60000, 28, 28)\n",
      "Training pixel type:    <class 'numpy.uint8'>\n",
      "Testing images shape:   (10000, 28, 28)\n",
      "Testing pixel type:     <class 'numpy.uint8'>\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      " 150  27   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# check out (again) dimensions and types of mnist data\n",
    "print('Training images shape: ', train_images.shape)\n",
    "print('Training pixel type:   ', type(train_images[0][0][0]))\n",
    "print('Testing images shape:  ', test_images.shape)\n",
    "print('Testing pixel type:    ', type(test_images[0][0][0]))\n",
    "\n",
    "print(train_images[0][15][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New training images shape:  (60000, 784)\n",
      "New training pixel type:    <class 'numpy.float32'>\n",
      "New testing images shape:   (10000, 784)\n",
      "New testing pixel type:     <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "# number of images\n",
    "Ntr = train_images.shape[0]\n",
    "Nts = test_images.shape[0]\n",
    "\n",
    "# image shape\n",
    "szx = train_images.shape[1]\n",
    "szy = train_images.shape[2]\n",
    "\n",
    "# need to reshape the 28x28 training/testing images as vectors\n",
    "train_images_vec = train_images.reshape((Ntr, szx * szy))\n",
    "test_images_vec = test_images.reshape(  (Nts, szx * szy))\n",
    "\n",
    "# deciding to normalize the pixels to 0..1 and recase as float32\n",
    "train_images_vec = train_images_vec.astype('float32') / 255\n",
    "test_images_vec = test_images_vec.astype('float32') / 255\n",
    "\n",
    "# display new input dimensions/type\n",
    "print('New training images shape: ', train_images_vec.shape)\n",
    "print('New training pixel type:   ', type(train_images_vec[0][0]))\n",
    "print('New testing images shape:  ', test_images_vec.shape)\n",
    "print('New testing pixel type:    ', type(test_images_vec[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reformat training and testing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape:  (60000,)\n",
      "Training labels type:   <class 'numpy.uint8'>\n",
      "\n",
      "First 9 training labels as labels:\n",
      " [5 0 4 1 9 2 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "# check out dimensions and types of mnist data\n",
    "print('Training labels shape: ', train_labels.shape)\n",
    "print('Training labels type:  ', type(train_labels[0]))\n",
    "print()\n",
    "\n",
    "# check out what the first 9 labels look like\n",
    "print(\"First 9 training labels as labels:\\n\", train_labels[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 9 training labels as one-hot encoded vectors:\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# also need to categorically encode the labels as \"one hot\"\n",
    "\n",
    "train_labels_onehot = to_categorical(train_labels)\n",
    "test_labels_onehot = to_categorical(test_labels)\n",
    "\n",
    "print(\"First 9 training labels as one-hot encoded vectors:\\n\", train_labels_onehot[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New training labels shape (one hot):  (60000, 10)\n",
      "New training labels type (one hot):   <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "# display new output dimensions/type\n",
    "print('New training labels shape (one hot): ', train_labels_onehot.shape)\n",
    "print('New training labels type (one hot):  ', type(train_labels_onehot[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define and train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "layer name : dense | input shape : (None, 784) | output shape : (None, 10)\n",
      "\n",
      "{'name': 'dense', 'trainable': True, 'batch_input_shape': (None, 784), 'dtype': 'float32', 'units': 10, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import tools for basic keras networks \n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "nout = 10\n",
    "\n",
    "# create architecture of simple neural network model\n",
    "# input layer  : 28*28 = 784 input nodes\n",
    "# output layer : 10 (nout) output nodes\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(nout, \n",
    "                         activation='sigmoid', \n",
    "                         input_shape=(szx * szy,)))\n",
    "\n",
    "# print a model summary\n",
    "print(network.summary())\n",
    "print()\n",
    "for layer in network.layers:\n",
    "    print('layer name : {} | input shape : {} | output shape : {}'.format(layer.name, layer.input.shape, layer.output.shape))\n",
    "print()\n",
    "for layer in network.layers:\n",
    "    print(layer.get_config())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 [==============================] - 2s 3ms/step - loss: 0.1414 - accuracy: 0.1133 - val_loss: 0.1051 - val_accuracy: 0.1968\n",
      "Epoch 2/20\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.0975 - accuracy: 0.2791 - val_loss: 0.0919 - val_accuracy: 0.3468\n",
      "Epoch 3/20\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.0895 - accuracy: 0.3967 - val_loss: 0.0865 - val_accuracy: 0.4432\n",
      "Epoch 4/20\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.4712 - val_loss: 0.0828 - val_accuracy: 0.5118\n",
      "Epoch 5/20\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.0820 - accuracy: 0.5184 - val_loss: 0.0797 - val_accuracy: 0.5577\n",
      "Epoch 6/20\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0791 - accuracy: 0.5512 - val_loss: 0.0768 - val_accuracy: 0.5880\n",
      "Epoch 7/20\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0764 - accuracy: 0.5744 - val_loss: 0.0740 - val_accuracy: 0.6075\n",
      "Epoch 8/20\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.5954 - val_loss: 0.0715 - val_accuracy: 0.6285\n",
      "Epoch 9/20\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.6111 - val_loss: 0.0692 - val_accuracy: 0.6453\n",
      "Epoch 10/20\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0695 - accuracy: 0.6259 - val_loss: 0.0670 - val_accuracy: 0.6565\n",
      "Epoch 11/20\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.0676 - accuracy: 0.6383 - val_loss: 0.0651 - val_accuracy: 0.6678\n",
      "Epoch 12/20\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0658 - accuracy: 0.6493 - val_loss: 0.0632 - val_accuracy: 0.6778\n",
      "Epoch 13/20\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.6582 - val_loss: 0.0616 - val_accuracy: 0.6865\n",
      "Epoch 14/20\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0627 - accuracy: 0.6672 - val_loss: 0.0601 - val_accuracy: 0.6950\n",
      "Epoch 15/20\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0613 - accuracy: 0.6746 - val_loss: 0.0587 - val_accuracy: 0.7018\n",
      "Epoch 16/20\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0600 - accuracy: 0.6815 - val_loss: 0.0574 - val_accuracy: 0.7088\n",
      "Epoch 17/20\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.6886 - val_loss: 0.0562 - val_accuracy: 0.7170\n",
      "Epoch 18/20\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0578 - accuracy: 0.6949 - val_loss: 0.0551 - val_accuracy: 0.7228\n",
      "Epoch 19/20\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.0567 - accuracy: 0.7015 - val_loss: 0.0540 - val_accuracy: 0.7305\n",
      "Epoch 20/20\n",
      "422/422 [==============================] - 1s 3ms/step - loss: 0.0558 - accuracy: 0.7079 - val_loss: 0.0531 - val_accuracy: 0.7378\n",
      "Done training!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compile network\n",
    "network.compile(optimizer='sgd', \n",
    "                loss='mean_squared_error', \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# now train the network\n",
    "history = network.fit(train_images_vec, \n",
    "                      train_labels_onehot, \n",
    "                      verbose=True, \n",
    "                      validation_split=.1, \n",
    "                      epochs=20, \n",
    "                      batch_size=128)\n",
    "print('Done training!')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0545 - accuracy: 0.7218\n",
      "test_acc: 0.7218000292778015\n"
     ]
    }
   ],
   "source": [
    "# test network\n",
    "test_loss, test_acc = network.evaluate(test_images_vec, \n",
    "                                       test_labels_onehot, \n",
    "                                       verbose=True)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some pieces needed to complete Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W (784, 10) | B (10,)\n"
     ]
    }
   ],
   "source": [
    "# get learned network weights and biases\n",
    "\n",
    "W = network.layers[0].get_weights()[0]     # weights input to hidden\n",
    "B = network.layers[0].get_weights()[1]     # bias to hidden\n",
    "\n",
    "print('W {} | B {}'.format(W.shape, B.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step\n",
      "(784,)\n",
      "(1, 784)\n"
     ]
    }
   ],
   "source": [
    "# model predictions (all 10000 test images)\n",
    "out = network.predict(test_images_vec)\n",
    "\n",
    "# model predictions (a single test image)\n",
    "example = test_images_vec[123]\n",
    "print(example.shape)\n",
    "\n",
    "# vector passed to network.predict must be (?, 784)\n",
    "example = example.reshape((1,example.shape[0]))\n",
    "print(example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "##\n",
    "## Homework 3 Solution Area\n",
    "##\n",
    "\n",
    "## Q1. The original MNIST test_labels numpy array contains the digit value associated\n",
    "## with the corresponding digit image (test_images). The output from the network (from\n",
    "## out = network.predict(test_images_vec) above) contains the activations of the 10\n",
    "## output nodes for every test image presented to the network. Write a function that\n",
    "## takes the (10000,10) numpy array of output (of type float) activations and returns a \n",
    "## (10000,) numpy array of discrete digit classification by the network (of type int).\n",
    "## Specifically, create a test_decisions numpy array of the same size and type as the\n",
    "## MNIST test_labels array you started with. Whereas test_labels shows the correct\n",
    "## answer, test_decisions shows the ultimate decision by the network. Below you will use \n",
    "## both arrays to pull out test images that the network classifies correctly vs. incorrectly.\n",
    "##\n",
    "## To turn a numpy array of continuous output activations into a discrete digit classification,\n",
    "## just take the maximum output as the \"winner\" that \"takes all\", determining the classification.\n",
    "##\n",
    "## In your function, feel free to use for loops. Here, we are looking to see that you understand\n",
    "## how to use the outputs generated by the network, not whether you can program using the\n",
    "## most efficient Python style.\n",
    "\n",
    "### INSERT Q1 SOLUTION HERE ###\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "[0.1394147  0.06849113 0.16223828 0.192309   0.20510395 0.14025201\n",
      " 0.089983   0.786108   0.09230374 0.27509406]\n",
      "7\n",
      "7\n",
      "7\n",
      "False\n",
      "False\n",
      "[7. 2. 1. 0. 4. 1. 4. 9. 6. 7.]\n"
     ]
    }
   ],
   "source": [
    "# a cell where I'm just trying to get my bearings, can edit this later\n",
    "# what's the general shape of the outputs\n",
    "print(out.shape)\n",
    "# what do the values inside there look like?\n",
    "print(out[0,:])\n",
    "# which one of those values is the largest?\n",
    "print(np.argmax(out[0,:]))\n",
    "print(np.argmax(out[0][:]))\n",
    "# hey this is great, argmax tells me which output unit was the winner!\n",
    "# now where can I find the right answer, the actual identity of the digit?\n",
    "print(test_labels[0])\n",
    "# will return true if the network got this one wrong\n",
    "print(not (np.argmax(out[0,:])==test_labels[0]))\n",
    "print(np.argmax(out[0,:])!=test_labels[0])\n",
    "# I kind of want to confirm that this is really a 7, I'm going to look at the \n",
    "# image. I know I don't have to do this for Q1 but it's a sanity check, I'll delete \n",
    "# it before submitting\n",
    "# fig = plt.figure()\n",
    "# plt.tight_layout()\n",
    "# plt.imshow(test_images[0], cmap='gray', interpolation='none')\n",
    "# plt.title(\"Digit: {}\".format(test_labels[0]))\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "# plt.show()\n",
    "\n",
    "# ok I gotta inspect every single output I guess\n",
    "test_decisions = np.zeros((10000,))\n",
    "for i in np.arange(out.shape[0]):\n",
    "    test_decisions[i] = np.argmax(out[i,:])\n",
    "\n",
    "print(test_decisions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Q2. Comparing the correct answers (test_labels) and network classifications (test_decisions),\n",
    "## for each digit 0..9, find one test image (test_image) that is classified by the network\n",
    "## correctly and one test image that is classified by the network incorrectly. \n",
    "##\n",
    "## Create a 2x10 plot of digit images (feel free to adapt the code above that uses subplot), with a \n",
    "## column for each digit 0..9 with the first row showing examples correctly classified (one example \n",
    "## for each digit) and the second row showing the examples incorrectly classified (one example \n",
    "## for each digit). Each subplot title should show the answer and the classification response \n",
    "## (e.g., displaying 4/2 as the title, if the correct answer is 4 and the classification was 2).\n",
    "##\n",
    "\n",
    "### INSERT Q2 SOLUTION HERE ###\n",
    "\n",
    "perf_for_each = np.zeros(test_decisions.shape[0])\n",
    "for i in np.arange(test_decisions.shape[0]):\n",
    "    perf_for_each[i] = test_decisions[i]==test_labels[i]\n",
    "\n",
    "print(perf_for_each[:10])\n",
    "\n",
    "# iterate through digits 0-9\n",
    "this_digit_correct = np.zeros((10,test_decisions.shape[0]))\n",
    "for i in np.arange(10):\n",
    "    for j in np.arange(test_decisions.shape[0]):\n",
    "        this_digit_correct[i,j] = perf_for_each[j] and test_labels[j]==i\n",
    "\n",
    "print(this_digit_correct[:3,:10])\n",
    "print(test_labels[:10])\n",
    "\n",
    "# ok, I know I've got code up there that will make images \n",
    "# so I have to find specific cases where the network was right, and cases where the \n",
    "# network was wrong\n",
    "# I've got a big array of network decisions, and another array of the actual labels\n",
    "# so... if the network makes the right decision, those two numbers should be the same\n",
    "# and if the network makes a mistake, those two numbers should be different\n",
    "# I have to find correct examples for each digit and incorrect examples for each digit\n",
    "# I guess I should make a for loop that iterates over the 10 digits\n",
    "# maybe I could make a 10000-element list saying whether each decision was right or wrong? \n",
    "\n",
    "# ugh did Jordan say anything about this on Piazza?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10)\n",
      "[[ 6.8257220e-02 -1.1302002e-02 -8.5116401e-03 -8.6710274e-02\n",
      "   4.1322418e-02]\n",
      " [ 6.2772386e-02 -8.2709275e-02  6.3708700e-02  1.1173934e-03\n",
      "   5.7888605e-02]\n",
      " [ 8.2926355e-02  6.5980107e-03  1.4114305e-02 -5.6733005e-02\n",
      "   8.0621578e-02]\n",
      " [-2.7468093e-02  2.0901956e-02 -6.5406904e-02 -8.4520787e-02\n",
      "   7.1677051e-02]\n",
      " [ 4.3119863e-03 -4.4009835e-03  1.2665592e-02  6.2569976e-05\n",
      "  -6.9151424e-02]]\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Q3. Create \"images\" of the connection weight adapting the code used to display\n",
    "## the actual digit images. There should be 10 weight images, an image for each\n",
    "## set of weight connecting the input layer (784 inputs) to each output node.\n",
    "## You will want to reshape the (784,1) vector of weights to a (28,28) image and\n",
    "## display the result using imshow()\n",
    "\n",
    "### INSERT Q3 SOLUTION HERE ###\n",
    "\n",
    "# ok, I know how to make an image using that code above\n",
    "\n",
    "# I guess I have to find the weights, and then make an image out of that?\n",
    "# ok looks like there's a cell up above that specifically grabs the weights \n",
    "# from the trained network, I should copy that code down here\n",
    "W = network.layers[0].get_weights()[0]\n",
    "# weights shape: (784, 10)\n",
    "print(W.shape)\n",
    "print(W[:5,:5])\n",
    "\n",
    "# but the images are 28x28, and these weights are definitely not 28x28!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.82016\n",
      "0.1394146696813153\n",
      "0.1394147\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Q4. Use the weight matrix (W), bias vector (B), and activation function (simple sigmoid)\n",
    "## to reproduce in your own code the outputs (out) generated by the network (from\n",
    "## this out = network.predict(test_images_vec))\n",
    "##\n",
    "## The simple sigmoid activation function is defined as follows:\n",
    "## f(x) = 1 / (1+exp(-x))\n",
    "##\n",
    "## Confirm that your output vectors and the keras-produced output vectors are the same\n",
    "## (within some small epsilon since floating point calculations will often not come out\n",
    "## exactly the same on computers).\n",
    "##\n",
    "\n",
    "### INSERT Q4 SOLUTION HERE ###\n",
    "\n",
    "# grab the first test_image\n",
    "first_pattern = test_images_vec[0,:]\n",
    "# grab the weights that connect to the first output unit\n",
    "# weights shape: (784, 10)\n",
    "netin_to_out0 = np.dot(first_pattern,W[:,0]) + B[0]\n",
    "# plug that into the sigmoid\n",
    "temp_act = 1 / (1+np.exp(-netin_to_out0))\n",
    "\n",
    "print(netin_to_out0)\n",
    "print(temp_act)\n",
    "print(out[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3730d5d1c31a0f0507cb21031ee0b4e9aa5b7079f3ceca5ddb3f252bb92fdf07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
