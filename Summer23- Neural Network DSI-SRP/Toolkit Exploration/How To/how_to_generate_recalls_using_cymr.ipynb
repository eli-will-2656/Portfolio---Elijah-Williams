{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use implementations of the CMR model to generate free recalls. We will change the existing code for the retrieval competition to take into account the concreteness of each sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) Load in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we transform our free recall data into format that can be used to train the CMR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2226\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>position</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>item</th>\n",
       "      <th>item_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>study</td>\n",
       "      <td>Smaller and larger abscesses may require diffe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  list  position trial_type  \\\n",
       "0        0     0         1      study   \n",
       "\n",
       "                                                item  item_index  \n",
       "0  Smaller and larger abscesses may require diffe...           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from cymr import fit, cmr\n",
    "import numpy as np\n",
    "\n",
    "# (0) Load in data\n",
    "our_df = pd.read_csv(\"C:/Summer 2023 - DSI-SRP/featureFR/Recall Analysis/data/psifr_al1_sl.csv\")\n",
    "\n",
    "\n",
    "# (1) Create function to a number to each sentence\n",
    "def assign_item_number(story_list: str, passage: int, item: int):\n",
    "    \"\"\"Assign item number based on story_list, passage, and item of the sentence.\n",
    "\n",
    "    Args:\n",
    "        story_list (str): e.g. 'A',\n",
    "        passage (int): e.g. 1\n",
    "        item (int): e.g. 0\n",
    "    \"\"\"\n",
    "    item_number = 100*(ord(story_list) - ord('A'))  + 20*(passage - 1) + item\n",
    "    return item_number\n",
    "\n",
    "assign_item_number(story_list=\"B\",passage=1,item=1)\n",
    "\n",
    "# (1.1) Add item numbers to dataframe\n",
    "story_list_col = our_df.story_list.to_list()\n",
    "passage_col = our_df.passage.to_list()\n",
    "item = our_df.item.to_list()\n",
    "\n",
    "item_numbers = [assign_item_number(story_list_col[i], passage_col[i], item[i]) for i in range(len(our_df))]\n",
    "our_df[\"item_index\"]  = item_numbers\n",
    "our_df.head(1)\n",
    "\n",
    "# (1.2) Create formatted dataframe\n",
    "cmr_columns = ['subject', 'list', 'position', 'trial_type', 'item', 'item_index']\n",
    "data_lst = []\n",
    "\n",
    "for index, row in our_df.iterrows():\n",
    "    if row[\"study\"]:\n",
    "        study_item = [\n",
    "            row[\"subject\"],\n",
    "            row[\"list\"],\n",
    "            row[\"input\"],\n",
    "            \"study\",\n",
    "            row[\"item_string\"],\n",
    "            row[\"item_index\"]\n",
    "        ]\n",
    "        data_lst.append(study_item)\n",
    "    if row[\"recall\"]:\n",
    "        recall_item = [\n",
    "            row[\"subject\"],\n",
    "            row[\"list\"],\n",
    "            int(row[\"output\"]),\n",
    "            \"recall\",\n",
    "            row[\"item_string\"],\n",
    "            row[\"item_index\"]\n",
    "        ]\n",
    "        data_lst.append(recall_item)\n",
    "        \n",
    "our_data = pd.DataFrame(data_lst, \n",
    "                           columns = cmr_columns).sort_values([\"subject\", \"list\", \"trial_type\", \"position\"], \n",
    "                                                              ascending=[True, True, False, True],\n",
    "                                                              ignore_index=True)\n",
    "print(len(our_data))\n",
    "our_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Fit Data to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'par' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 43\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39m# print(par)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m# (2) Create Model using Parameters\u001b[39;00m\n\u001b[0;32m     42\u001b[0m model \u001b[39m=\u001b[39m cmr\u001b[39m.\u001b[39mCMR()\n\u001b[1;32m---> 43\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit_indiv(our_data, par, patterns\u001b[39m=\u001b[39mpatterns, tol\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m, n_rep\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     44\u001b[0m best \u001b[39m=\u001b[39m fit\u001b[39m.\u001b[39mget_best_results(results)\n\u001b[0;32m     45\u001b[0m \u001b[39m# logl = logarithm of the probability of the participant's recall sequence according to the model\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39m# k = number of free parameters\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39m# n = number of data points (tested before found acceptable fit)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'par' is not defined"
     ]
    }
   ],
   "source": [
    "# (0) Calculate the probability of not remembering anything\n",
    "our_data.head()\n",
    "groupby_columns = [\"subject\", \"list\"]\n",
    "num_empty_recalls = 0 \n",
    "for trial_index, trial in enumerate(our_data.groupby(groupby_columns)):\n",
    "    trial = trial[1]\n",
    "    if len(trial) ==  trial.trial_type.value_counts()[\"study\"]:    # IF participant does not recall anything\n",
    "        num_empty_recalls += 1\n",
    "\n",
    "prob_not_recalling_anything = num_empty_recalls / trial_index\n",
    "prob_not_recalling_anything\n",
    "\n",
    "import numpy as np \n",
    "## (1.1) Create a parameter object (represents the parameters of a CMR model)\n",
    "param_def = cmr.CMRParameters()\n",
    "param_def.set_fixed(T=0.1, X1=prob_not_recalling_anything)\n",
    "param_def.set_free(B_enc=(0.01, .999), \n",
    "             B_start=(0.01, .999), \n",
    "             B_rec=(0.01, .999), \n",
    "             X2=(0.01, .999), \n",
    "             Lfc=(0.01, .999), \n",
    "             Lcf=(0.01, .999),\n",
    "             P1=(0.01, .999),\n",
    "             P2=(0.5, 4))\n",
    "\n",
    "param_def.set_dependent(Dfc='1 - Lfc', Dcf='1 - Lcf')\n",
    "\n",
    "## (1.2) Grab all the studied items and associate them with a pattern in the model\n",
    "n_items = our_data.item_index.max() + 1\n",
    "loc_patterns = np.eye(n_items)\n",
    "items = our_data.groupby('item_index')['item'].first().to_numpy()      # List of all the study items, based on their item index\n",
    "patterns = {'items': items, 'vector': {'loc': loc_patterns}}        # List of items and patterns they correspond to\n",
    "\n",
    "# (1.3) Set up the weights connecting the two layers of the model\n",
    "param_def.set_sublayers(f=['task'], c=['task'])\n",
    "weights = {(('task', 'item'), ('task', 'item')): 'loc'}\n",
    "param_def.set_weights('fc', weights)\n",
    "param_def.set_weights('cf', weights)\n",
    "# print(par)\n",
    "\n",
    "# (2) Create Model using Parameters\n",
    "model = cmr.CMR()\n",
    "results = model.fit_indiv(our_data, par, patterns=patterns, tol=0.05, n_rep=1)\n",
    "best = fit.get_best_results(results)\n",
    "# logl = logarithm of the probability of the participant's recall sequence according to the model\n",
    "# k = number of free parameters\n",
    "# n = number of data points (tested before found acceptable fit)\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_parameters = best.T.to_dict()\n",
    "subj_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Simulate Free Recall Using CMR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cmr.study_list` is a function that presents a bunch of items to a network and the CMR model change its weights in response. Then at the end, the start item is presented again (representing 'tell me everything you can remember about the passage in as much possible')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Additional Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subject(\n",
    "    cmr_network, study, recall, param, param_def=None, patterns=None, **kwargs\n",
    "):\n",
    "    cmr_network.set_default_options(param_def)      # Set default the parameter options\n",
    "    n_item = len(study['input'][0])     # = 20\n",
    "    n_list = len(study['input'])        # = 4 (variable)\n",
    "    if param_def is None:\n",
    "        raise ValueError('Must provide a Parameters object.')\n",
    "    \n",
    "    n_sub = len(param_def.sublayers['c'])   # = 1\n",
    "    param = cmr.prepare_list_param(n_item, n_sub, param, param_def)     # Changes the learning rates into an array of 20 values, Add probability of stopping at each index\n",
    "\n",
    "    item_index = np.arange(len(patterns['items']))  # [0, 1, 2, ..., 79]\n",
    "    recalls_list = []\n",
    "    for i in range(n_list):     # for each list\n",
    "        # access the dynamic parameters needed for this list\n",
    "        list_param = param.copy()\n",
    "        list_param = param_def.get_dynamic(list_param, i)              # Parameters should not change with list (do not need to worry about that)\n",
    "\n",
    "        # simulate study\n",
    "        item_pool, item_study, item_recall = cmr.get_list_items(                   # item_pool = [20, 21, 22, ..., 39]\n",
    "            item_index, study, recall, i, param_def.options['scope']               # item_study = [0, 1, ..., 19]\n",
    "                                                                                # item_recall  = [1,5,3,8,19]\n",
    "        )\n",
    "        net = cmr.study_list(param_def, list_param, item_pool, item_study, patterns)   # Creates network that has studied items\n",
    "\n",
    "        # simulate recall\n",
    "        recall_index = net.generate_recall(\n",
    "            ('task', 'item'),\n",
    "            net.c_sublayers,\n",
    "            list_param['B_rec'],\n",
    "            list_param['T'],\n",
    "            prob_of_ending,\n",
    "        )\n",
    "\n",
    "        items = patterns['items'][item_pool]\n",
    "        recall_items = items[recall_index]\n",
    "        recalls_list.append(recall_items)\n",
    "        \n",
    "    return recalls_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Copied Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subject(\n",
    "    self, study, recall, param, param_def=None, patterns=None, **kwargs\n",
    "):\n",
    "    self.set_default_options(param_def)\n",
    "    n_item = len(study['input'][0])\n",
    "    n_list = len(study['input'])\n",
    "    if param_def is None:\n",
    "        raise ValueError('Must provide a Parameters object.')\n",
    "    n_sub = len(param_def.sublayers['c'])\n",
    "    param = prepare_list_param(n_item, n_sub, param, param_def)\n",
    "\n",
    "    item_index = np.arange(len(patterns['items']))\n",
    "    recalls_list = []\n",
    "    for i in range(n_list):\n",
    "        # access the dynamic parameters needed for this list\n",
    "        list_param = param.copy()\n",
    "        list_param = param_def.get_dynamic(list_param, i)\n",
    "\n",
    "        # simulate study\n",
    "        item_pool, item_study, item_recall = get_list_items(\n",
    "            item_index, study, recall, i, param_def.options['scope']\n",
    "        )\n",
    "        net = study_list(param_def, list_param, item_pool, item_study, patterns)\n",
    "\n",
    "        # simulate recall\n",
    "        if param_def.options['filter_recalls']:\n",
    "            recall_index = net.generate_recall(\n",
    "                ('task', 'item'),\n",
    "                net.c_sublayers,\n",
    "                list_param['B_rec'],\n",
    "                list_param['T'],\n",
    "                list_param['p_stop'],\n",
    "                filter_recalls=True,\n",
    "                A1=list_param['A1'],\n",
    "                A2=list_param['A2'],\n",
    "            )\n",
    "        else:\n",
    "            recall_index = net.generate_recall(\n",
    "                ('task', 'item'),\n",
    "                net.c_sublayers,\n",
    "                list_param['B_rec'],\n",
    "                list_param['T'],\n",
    "                list_param['p_stop'],\n",
    "            )\n",
    "\n",
    "        items = patterns['items'][item_pool]\n",
    "        recall_items = items[recall_index]\n",
    "        recalls_list.append(recall_items)\n",
    "    return recalls_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hacking in recall simulation\n",
    "It looks like the function we want to hack into in order to influence how information is recalled in `net.generate_recall()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CMR' object has no attribute 'get_segment'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rec_ind \u001b[39m=\u001b[39m my_cmr_network\u001b[39m.\u001b[39;49mget_segment(\u001b[39m'\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m, (\u001b[39m'\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mitem\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      2\u001b[0m n_item \u001b[39m=\u001b[39m rec_ind[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m rec_ind[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CMR' object has no attribute 'get_segment'"
     ]
    }
   ],
   "source": [
    "rec_ind = my_cmr_network.get_segment('f', ('task', 'item'))\n",
    "n_item = rec_ind[1] - rec_ind[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.generate_recall(\n",
    "                ('task', 'item'),\n",
    "                net.c_sublayers,\n",
    "                list_param['B_rec'],\n",
    "                list_param['T'],\n",
    "                prob_of_ending,\n",
    "            )\n",
    "def generate_recall(\n",
    "        cmr_network,\n",
    "        segment,\n",
    "        sublayers,\n",
    "        B,\n",
    "        T,\n",
    "        p_stop,\n",
    "        amin=0.000001,\n",
    "        filter_recalls=False,\n",
    "        A1=None,\n",
    "        A2=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generate a sequence of simulated free recall events.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        segment : tuple of str, str\n",
    "            Sublayer and segment to retrieve items from.\n",
    "\n",
    "        sublayers : str or list of str\n",
    "            Sublayer(s) of context to update.\n",
    "\n",
    "        B : float or numpy.ndarray\n",
    "            Context updating rate after each recall.\n",
    "\n",
    "        T : float\n",
    "            Decision parameter for choice rule.\n",
    "\n",
    "        p_stop : numpy.array\n",
    "            Probability of stopping at each output position.\n",
    "\n",
    "        amin : float, optional\n",
    "            Minimum activation of each not-yet-recalled item on each\n",
    "            recall attempt.\n",
    "\n",
    "        filter_recalls : bool, optional\n",
    "            If true, potential recalls will be filtered based on match\n",
    "            to context.\n",
    "\n",
    "        A1 : float, optional\n",
    "            Intercept mapping context match to an expit to determine\n",
    "            recovery probability.\n",
    "\n",
    "        A2 : float, optional\n",
    "            Slope mapping match to an expit.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        recalls : list of int\n",
    "            Indices of items recalled at each output position.\n",
    "        \"\"\"\n",
    "        if not isinstance(sublayers, list):\n",
    "            sublayers = [sublayers]\n",
    "\n",
    "        # weights to use for recall (assume fixed during recall)\n",
    "        rec_ind = cmr_network.get_segment('f', *segment)\n",
    "        n_item = rec_ind[1] - rec_ind[0]\n",
    "        # n_sub = len(sublayers)\n",
    "        # param = prepare_recall_param(n_item, n_sub, B, T, amin)\n",
    "\n",
    "        # recalls = []\n",
    "        # exclude = np.zeros(n_item, dtype=np.dtype('i'))\n",
    "        # item_ind = np.arange(n_item)\n",
    "        # for i in range(n_item):\n",
    "        #     # stop recall with some probability\n",
    "        #     if np.random.rand() < p_stop[i]:\n",
    "        #         break\n",
    "\n",
    "        #     # calculate item support\n",
    "        #     operations.cue_item(\n",
    "        #         rec_ind[0],\n",
    "        #         n_item,\n",
    "        #         self.w_cf_pre,\n",
    "        #         self.w_cf_exp,\n",
    "        #         self.w_ff_pre,\n",
    "        #         self.w_ff_exp,\n",
    "        #         self.f_in,\n",
    "        #         self.c,\n",
    "            #     exclude,\n",
    "            #     np.asarray(recalls, dtype=np.dtype('i')),\n",
    "            #     i,\n",
    "            # )\n",
    "            # operations.apply_softmax(\n",
    "            #     rec_ind[0], n_item, self.f_in, exclude, amin, param['T']\n",
    "            # )\n",
    "\n",
    "            # # select item for recall proportionate to support\n",
    "            # support = self.f_in[rec_ind[0] : rec_ind[1]]\n",
    "            # p_recall = support / np.sum(support)\n",
    "\n",
    "            # if filter_recalls:\n",
    "            #     # acceptance probability based on context match\n",
    "            #     operations.item_match(\n",
    "            #         rec_ind[0], n_item, self.w_fc_pre, self.w_fc_exp, self.c, self.match\n",
    "            #     )\n",
    "            #     operations.apply_expit(rec_ind[0], n_item, self.match, A1, A2)\n",
    "\n",
    "            #     # recall probabiity is selection + acceptance\n",
    "            #     p_recall = p_recall * self.match[rec_ind[0] : rec_ind[1]]\n",
    "\n",
    "            #     # rescale probability to vary between 0 and 1\n",
    "            #     p_recall = p_recall / np.sum(p_recall)\n",
    "\n",
    "            # if np.any(np.isnan(p_recall)):\n",
    "            #     n = np.count_nonzero(exclude == 0)\n",
    "            #     p_recall[exclude == 0] = 1 / n\n",
    "            #     p_recall[exclude == 1] = 0\n",
    "            #     recall = np.random.choice(item_ind, p=p_recall)\n",
    "            # else:\n",
    "            #     recall = np.random.choice(item_ind, p=p_recall)\n",
    "            # recalls.append(recall)\n",
    "            # exclude[recall] = 1\n",
    "\n",
    "            # # integrate context associated with the item into context\n",
    "        #     item = (*segment, recall)\n",
    "        #     self.integrate(item, sublayers, param['B'][i])\n",
    "        # return recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recall(\n",
    "        self,\n",
    "        segment,\n",
    "        sublayers,\n",
    "        B,\n",
    "        T,\n",
    "        p_stop,\n",
    "        amin=0.000001,\n",
    "        filter_recalls=False,\n",
    "        A1=None,\n",
    "        A2=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generate a sequence of simulated free recall events.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        segment : tuple of str, str\n",
    "            Sublayer and segment to retrieve items from.\n",
    "\n",
    "        sublayers : str or list of str\n",
    "            Sublayer(s) of context to update.\n",
    "\n",
    "        B : float or numpy.ndarray\n",
    "            Context updating rate after each recall.\n",
    "\n",
    "        T : float\n",
    "            Decision parameter for choice rule.\n",
    "\n",
    "        p_stop : numpy.array\n",
    "            Probability of stopping at each output position.\n",
    "\n",
    "        amin : float, optional\n",
    "            Minimum activation of each not-yet-recalled item on each\n",
    "            recall attempt.\n",
    "\n",
    "        filter_recalls : bool, optional\n",
    "            If true, potential recalls will be filtered based on match\n",
    "            to context.\n",
    "\n",
    "        A1 : float, optional\n",
    "            Intercept mapping context match to an expit to determine\n",
    "            recovery probability.\n",
    "\n",
    "        A2 : float, optional\n",
    "            Slope mapping match to an expit.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        recalls : list of int\n",
    "            Indices of items recalled at each output position.\n",
    "        \"\"\"\n",
    "        if not isinstance(sublayers, list):\n",
    "            sublayers = [sublayers]\n",
    "\n",
    "        # weights to use for recall (assume fixed during recall)\n",
    "        rec_ind = self.get_segment('f', *segment)\n",
    "        n_item = rec_ind[1] - rec_ind[0]\n",
    "        n_sub = len(sublayers)\n",
    "        param = prepare_recall_param(n_item, n_sub, B, T, amin)\n",
    "\n",
    "        recalls = []\n",
    "        exclude = np.zeros(n_item, dtype=np.dtype('i'))\n",
    "        item_ind = np.arange(n_item)\n",
    "        for i in range(n_item):\n",
    "            # stop recall with some probability\n",
    "            if np.random.rand() < p_stop[i]:\n",
    "                break\n",
    "\n",
    "            # calculate item support\n",
    "            operations.cue_item(\n",
    "                rec_ind[0],\n",
    "                n_item,\n",
    "                self.w_cf_pre,\n",
    "                self.w_cf_exp,\n",
    "                self.w_ff_pre,\n",
    "                self.w_ff_exp,\n",
    "                self.f_in,\n",
    "                self.c,\n",
    "                exclude,\n",
    "                np.asarray(recalls, dtype=np.dtype('i')),\n",
    "                i,\n",
    "            )\n",
    "            operations.apply_softmax(\n",
    "                rec_ind[0], n_item, self.f_in, exclude, amin, param['T']\n",
    "            )\n",
    "\n",
    "            # select item for recall proportionate to support\n",
    "            support = self.f_in[rec_ind[0] : rec_ind[1]]\n",
    "            p_recall = support / np.sum(support)\n",
    "\n",
    "            if filter_recalls:\n",
    "                # acceptance probability based on context match\n",
    "                operations.item_match(\n",
    "                    rec_ind[0], n_item, self.w_fc_pre, self.w_fc_exp, self.c, self.match\n",
    "                )\n",
    "                operations.apply_expit(rec_ind[0], n_item, self.match, A1, A2)\n",
    "\n",
    "                # recall probabiity is selection + acceptance\n",
    "                p_recall = p_recall * self.match[rec_ind[0] : rec_ind[1]]\n",
    "\n",
    "                # rescale probability to vary between 0 and 1\n",
    "                p_recall = p_recall / np.sum(p_recall)\n",
    "\n",
    "            if np.any(np.isnan(p_recall)):\n",
    "                n = np.count_nonzero(exclude == 0)\n",
    "                p_recall[exclude == 0] = 1 / n\n",
    "                p_recall[exclude == 1] = 0\n",
    "                recall = np.random.choice(item_ind, p=p_recall)\n",
    "            else:\n",
    "                recall = np.random.choice(item_ind, p=p_recall)\n",
    "            recalls.append(recall)\n",
    "            exclude[recall] = 1\n",
    "\n",
    "            # integrate context associated with the item into context\n",
    "            item = (*segment, recall)\n",
    "            self.integrate(item, sublayers, param['B'][i])\n",
    "        return recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subject(\n",
    "    self, study, recall, param, param_def=None, patterns=None, **kwargs\n",
    "):\n",
    "    self.set_default_options(param_def)\n",
    "    n_item = len(study['input'][0])\n",
    "    n_list = len(study['input'])\n",
    "    if param_def is None:\n",
    "        raise ValueError('Must provide a Parameters object.')\n",
    "    n_sub = len(param_def.sublayers['c'])\n",
    "    param = prepare_list_param(n_item, n_sub, param, param_def)\n",
    "\n",
    "    item_index = np.arange(len(patterns['items']))\n",
    "    recalls_list = []\n",
    "    for i in range(n_list):\n",
    "        # access the dynamic parameters needed for this list\n",
    "        list_param = param.copy()\n",
    "        list_param = param_def.get_dynamic(list_param, i)\n",
    "\n",
    "        # simulate study\n",
    "        item_pool, item_study, item_recall = get_list_items(\n",
    "            item_index, study, recall, i, param_def.options['scope']\n",
    "        )\n",
    "        net = study_list(param_def, list_param, item_pool, item_study, patterns)\n",
    "\n",
    "        # simulate recall\n",
    "        if param_def.options['filter_recalls']:\n",
    "            recall_index = net.generate_recall(\n",
    "                ('task', 'item'),\n",
    "                net.c_sublayers,\n",
    "                list_param['B_rec'],\n",
    "                list_param['T'],\n",
    "                list_param['p_stop'],\n",
    "                filter_recalls=True,\n",
    "                A1=list_param['A1'],\n",
    "                A2=list_param['A2'],\n",
    "            )\n",
    "        else:\n",
    "            recall_index = net.generate_recall(\n",
    "                ('task', 'item'),\n",
    "                net.c_sublayers,\n",
    "                list_param['B_rec'],\n",
    "                list_param['T'],\n",
    "                list_param['p_stop'],\n",
    "            )\n",
    "\n",
    "        items = patterns['items'][item_pool]\n",
    "        recall_items = items[recall_index]\n",
    "        recalls_list.append(recall_items)\n",
    "    return recalls_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform simulated recall data into psifr format to perform nice analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
