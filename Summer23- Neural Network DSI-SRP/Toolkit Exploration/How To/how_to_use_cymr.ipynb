{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cymr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cymr is a python library (developed by Sean Polyn and Neale Morton) that contains code to implement the CMR model of memory retrieval. Let's take a look at what code this library has to offer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cymr\n",
    "\n",
    "# FIXME: Add visualization of the weight of CMR network after reading 20 sentences\n",
    "## Each node is a circle at a point, and create functions to draw lines of varying opacities between two points\n",
    "## Then use the weight matrix to add those lines and cricles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Note:` The two big questions I am hoping to find out are:\n",
    "\n",
    "1. How can I find the best parameters for CMR (to describe patterns in the data)?\n",
    "2. How can I simulate the free recall process using an implentation of the CMR model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (0) Load In Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we store our complete recall data in `our_df` and CMR-formmated data in `our_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2226\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>position</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>item</th>\n",
       "      <th>item_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>study</td>\n",
       "      <td>Smaller and larger abscesses may require diffe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  list  position trial_type  \\\n",
       "0        0     0         1      study   \n",
       "\n",
       "                                                item  item_index  \n",
       "0  Smaller and larger abscesses may require diffe...           0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from cymr import fit, cmr\n",
    "import numpy as np\n",
    "\n",
    "our_df = pd.read_csv(\"C:/Summer 2023 - DSI-SRP/featureFR/Recall Analysis/data/psifr_al1_sl.csv\")\n",
    "\n",
    "def assign_item_number(story_list: str, passage: int, item: int):\n",
    "    \"\"\"Assign item number based on story_list, passage, and item of the sentence.\n",
    "\n",
    "    Args:\n",
    "        story_list (str): e.g. 'A',\n",
    "        passage (int): e.g. 1\n",
    "        item (int): e.g. 0\n",
    "    \"\"\"\n",
    "    item_number = 100*(ord(story_list) - ord('A'))  + 20*(passage - 1) + item\n",
    "    return item_number\n",
    "\n",
    "assign_item_number(story_list=\"B\",passage=1,item=1)\n",
    "\n",
    "# (1.2) Add item numbers to dataframe\n",
    "story_list_col = our_df.story_list.to_list()\n",
    "passage_col = our_df.passage.to_list()\n",
    "item = our_df.item.to_list()\n",
    "\n",
    "item_numbers = [assign_item_number(story_list_col[i], passage_col[i], item[i]) for i in range(len(our_df))]\n",
    "our_df[\"item_index\"]  = item_numbers\n",
    "our_df.head(1)\n",
    "\n",
    "# (1.3) Format Data\n",
    "cmr_columns = ['subject', 'list', 'position', 'trial_type', 'item', 'item_index']\n",
    "data_lst = []\n",
    "\n",
    "for index, row in our_df.iterrows():\n",
    "    if row[\"study\"]:\n",
    "        study_item = [\n",
    "            row[\"subject\"],\n",
    "            row[\"list\"],\n",
    "            row[\"input\"],\n",
    "            \"study\",\n",
    "            row[\"item_string\"],\n",
    "            row[\"item_index\"]\n",
    "        ]\n",
    "        data_lst.append(study_item)\n",
    "    if row[\"recall\"]:\n",
    "        recall_item = [\n",
    "            row[\"subject\"],\n",
    "            row[\"list\"],\n",
    "            int(row[\"output\"]),\n",
    "            \"recall\",\n",
    "            row[\"item_string\"],\n",
    "            row[\"item_index\"]\n",
    "        ]\n",
    "        data_lst.append(recall_item)\n",
    "        \n",
    "our_data = pd.DataFrame(data_lst, \n",
    "                           columns = cmr_columns).sort_values([\"subject\", \"list\", \"trial_type\", \"position\"], \n",
    "                                                              ascending=[True, True, False, True],\n",
    "                                                              ignore_index=True)\n",
    "print(len(our_data))\n",
    "our_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (0.5) Evaluating a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31754\n"
     ]
    }
   ],
   "source": [
    "# (0) Loading in data \n",
    "from cymr import fit, cmr\n",
    "data = fit.sample_data('Morton2013_mixed')\n",
    "data = data[[\"subject\", \"list\", \"position\", \"trial_type\", \"item\", \"item_index\"]]\n",
    "data.head()\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sample data, each trial consists of people studying 24 items (photos of celebrities, objects, or locations), and then trying to remember as many of those items in any order. \n",
    "* This comes from a [2013 study](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3767960/) where a classifier was trained to predict the category of object a person was looking at based on oscillations in brain activity (measured by an EEG). \n",
    "  * The big question this research study is \"are there detectable neural signals that correpsond to a context-based retrieval cue, such as the category of an object?\" If here is then you should be able to spot these neural signals and use them to predict when a participant is going to recall an picture of the same type as the previous picture\n",
    "  * Recall that the CMR model says that people create a representation of time that items are tied to, which is then used as a retrieval-cue. This study adds to the model by suggesting people create category-based retrieval cues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>position</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>item</th>\n",
       "      <th>item_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>study</td>\n",
       "      <td>BRANDENBURG GATE</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>study</td>\n",
       "      <td>JENNE MOSQUE</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>study</td>\n",
       "      <td>USHER</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>study</td>\n",
       "      <td>NEWT GINGRICH</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>study</td>\n",
       "      <td>TOMATO</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>study</td>\n",
       "      <td>MICROSCOPE</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>study</td>\n",
       "      <td>ELIZABETH TAYLOR</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>study</td>\n",
       "      <td>FAITH HILL</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>study</td>\n",
       "      <td>BILLY CRYSTAL</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>study</td>\n",
       "      <td>MOUNT KILIMANJARO</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>study</td>\n",
       "      <td>QUINCY MARKET</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>study</td>\n",
       "      <td>NIAGARA FALLS</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>study</td>\n",
       "      <td>STAMP</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>study</td>\n",
       "      <td>SHELF</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>study</td>\n",
       "      <td>MASCARA</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>study</td>\n",
       "      <td>JESSICA SIMPSON</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>study</td>\n",
       "      <td>OWEN WILSON</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>study</td>\n",
       "      <td>LIAM NEESON</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>study</td>\n",
       "      <td>PEARL HARBOR</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>study</td>\n",
       "      <td>SALT LAKE TEMPLE</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>study</td>\n",
       "      <td>GRAND CANYON</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>study</td>\n",
       "      <td>BASEBALL BAT</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>study</td>\n",
       "      <td>HANGER</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>study</td>\n",
       "      <td>SURGE PROTECTOR</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>SURGE PROTECTOR</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>BASEBALL BAT</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>recall</td>\n",
       "      <td>JESSICA SIMPSON</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>recall</td>\n",
       "      <td>LIAM NEESON</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>recall</td>\n",
       "      <td>USHER</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>recall</td>\n",
       "      <td>ELIZABETH TAYLOR</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>recall</td>\n",
       "      <td>PEARL HARBOR</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>recall</td>\n",
       "      <td>NIAGARA FALLS</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>recall</td>\n",
       "      <td>HANGER</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subject  list  position trial_type               item  item_index\n",
       "80         1     4         1      study   BRANDENBURG GATE         278\n",
       "81         1     4         2      study       JENNE MOSQUE         353\n",
       "82         1     4         3      study              USHER         247\n",
       "83         1     4         4      study      NEWT GINGRICH         190\n",
       "84         1     4         5      study             TOMATO         740\n",
       "85         1     4         6      study         MICROSCOPE         651\n",
       "86         1     4         7      study   ELIZABETH TAYLOR          84\n",
       "87         1     4         8      study         FAITH HILL          87\n",
       "88         1     4         9      study      BILLY CRYSTAL          34\n",
       "89         1     4        10      study  MOUNT KILIMANJARO         395\n",
       "90         1     4        11      study      QUINCY MARKET         431\n",
       "91         1     4        12      study      NIAGARA FALLS         403\n",
       "92         1     4        13      study              STAMP         719\n",
       "93         1     4        14      study              SHELF         704\n",
       "94         1     4        15      study            MASCARA         645\n",
       "95         1     4        16      study    JESSICA SIMPSON         123\n",
       "96         1     4        17      study        OWEN WILSON         196\n",
       "97         1     4        18      study        LIAM NEESON         161\n",
       "98         1     4        19      study       PEARL HARBOR         416\n",
       "99         1     4        20      study   SALT LAKE TEMPLE         442\n",
       "100        1     4        21      study       GRAND CANYON         333\n",
       "101        1     4        22      study       BASEBALL BAT         528\n",
       "102        1     4        23      study             HANGER         608\n",
       "103        1     4        24      study    SURGE PROTECTOR         726\n",
       "104        1     4         1     recall    SURGE PROTECTOR         726\n",
       "105        1     4         2     recall       BASEBALL BAT         528\n",
       "106        1     4         3     recall    JESSICA SIMPSON         123\n",
       "107        1     4         4     recall        LIAM NEESON         161\n",
       "108        1     4         5     recall              USHER         247\n",
       "109        1     4         6     recall   ELIZABETH TAYLOR          84\n",
       "110        1     4         7     recall       PEARL HARBOR         416\n",
       "111        1     4         8     recall      NIAGARA FALLS         403\n",
       "112        1     4         9     recall             HANGER         608"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) Example of a trial\n",
    "data.query(\"subject == 1 and list == 4\")\n",
    "# data.query(\"item_index == 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) Associate each studied item with a pattern in the network \n",
    "n_items = 768       # 256 of each type of object\n",
    "loc_patterns = np.eye(n_items)\n",
    "loc_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': array(['ABRAHAM LINCOLN', 'ADAM SANDLER', 'AL GORE', 'AL PACINO',\n",
       "        'AL SHARPTON', 'ALBERT EINSTEIN', 'ALEC BALDWIN', 'ALEX RODRIGUEZ',\n",
       "        'ALEX TREBEK', 'ALICIA KEYS', 'ALLEN IVERSON', 'ANDRE3000',\n",
       "        'ANDRE AGASSI', 'ANGELINA JOLIE', 'ANNETTE BENING',\n",
       "        'ANTHONY HOPKINS', 'ANTONIO BANDERAS', 'ARNOLD SCHWARZENEGGER',\n",
       "        'ASHTON KUTCHER', 'AUDREY HEPBURN', 'AUDREY TATOU', 'BABE RUTH',\n",
       "        'BARBARA WALTERS', 'BARRY BONDS', 'BEN KINGSLEY', 'BEN STILLER',\n",
       "        'BENICIO DEL TORO', 'BENJAMIN FRANKLIN', 'BILL CLINTON',\n",
       "        'BILL COSBY', 'BILL GATES', 'BILL MAHER', 'BILL MURRAY',\n",
       "        'BILLY BOB THORNTON', 'BILLY CRYSTAL', 'BOB DOLE', 'BOB DYLAN',\n",
       "        'BOB SAGET', 'BONO', 'BRAD PITT', 'BRITNEY SPEARS',\n",
       "        'BRITTANY MURPHY', 'BRUCE LEE', 'BRUCE SPRINGSTEEN',\n",
       "        'BRUCE WILLIS', 'CAMERON DIAZ', 'CARROT TOP', 'CARY GRANT',\n",
       "        'CATHERINE ZETA JONES', 'CHARLIE SHEEN', 'CHARLIZE THERON',\n",
       "        'CHE GUEVARA', 'CHER', 'CHRIS FARLEY', 'CHRISTOPHER REEVE',\n",
       "        'CHRISTOPHER WALKEN', 'CINDY CRAWFORD', 'CLIVE OWEN',\n",
       "        'COLIN FARRELL', 'COLIN POWELL', \"CONAN O'BRIEN\",\n",
       "        'CONDOLEEZZA RICE', 'COURTENEY COX', 'COURTNEY LOVE', 'DALAI LAMA',\n",
       "        'DAN RATHER', 'DANE COOK', 'DANNY DEVITO', 'DAVE MATTHEWS',\n",
       "        'DAVID BECKHAM', 'DAVID DUCHOVNY', 'DAVID HASSELHOFF',\n",
       "        'DAVID SPADE', 'DEBRA MESSING', 'DEMI MOORE', 'DENZEL WASHINGTON',\n",
       "        'DEREK JETER', 'DICK CHENEY', 'DOLLY PARTON', 'DONALD RUMSFELD',\n",
       "        'DONALD TRUMP', 'DREW BARRYMORE', 'DUSTIN HOFFMAN',\n",
       "        'DWIGHT EISENHOWER', 'ELIZABETH TAYLOR', 'ELVIS PRESLEY', 'EMINEM',\n",
       "        'FAITH HILL', 'FRAN DRESCHER', 'FRANKLIN D ROOSEVELT',\n",
       "        'FREDDIE MERCURY', 'GARTH BROOKS', 'GENE HACKMAN',\n",
       "        'GEORGE CLOONEY', 'GEORGE W BUSH', 'GEORGE WASHINGTON',\n",
       "        'GLENN CLOSE', 'GWEN STEFANI', 'GWYNETH PALTROW',\n",
       "        'HALEY JOEL OSMENT', 'HALLE BERRY', 'HARRISON FORD',\n",
       "        'HEATHER GRAHAM', 'HELEN HUNT', 'HILARY DUFF', 'HILLARY CLINTON',\n",
       "        'HOWARD STERN', 'HUGH GRANT', 'HULK HOGAN', 'JACK BLACK',\n",
       "        'JACK NICHOLSON', 'JACKIE CHAN', 'JACKIE KENNEDY',\n",
       "        'JACQUES CHIRAC', 'JAMIE FOXX', 'JANE FONDA', 'JANET RENO',\n",
       "        'JASON ALEXANDER', 'JASON BIGGS', 'JAY LENO', 'JENNIFER ANISTON',\n",
       "        'JENNIFER LOPEZ', 'JERRY SEINFELD', 'JESSICA SIMPSON',\n",
       "        'JIM BELUSHI', 'JIM CARREY', 'JIM MORRISON', 'JIMI HENDRIX',\n",
       "        'JIMMY CARTER', 'JOAN RIVERS', 'JOAQUIN PHOENIX', 'JODIE FOSTER',\n",
       "        'JOE DIMAGGIO', 'JOHN EDWARDS', 'JOHN F KENNEDY', 'JOHN KERRY',\n",
       "        'JOHN LENNON', 'JOHN LITHGOW', 'JOHN MCCAIN', 'JOHN TRAVOLTA',\n",
       "        'JOHN WAYNE', 'JOHNNY DEPP', 'JON STEWART', 'JON VOIGHT',\n",
       "        'JULIA ROBERTS', 'JULIANNE MOORE', 'JUSTIN TIMBERLAKE',\n",
       "        'KATE WINSLET', 'KATIE COURIC', 'KATIE HOLMES', 'KEANU REEVES',\n",
       "        'KEIRA KNIGHTLEY', 'KEN GRIFFEY', 'KEVIN SPACEY', 'KIRSTEN DUNST',\n",
       "        'KOBE BRYANT', 'KURT COBAIN', 'LANCE ARMSTRONG', 'LARRY KING',\n",
       "        'LEBRON JAMES', 'LEONARDO DICAPRIO', 'LIAM NEESON',\n",
       "        'LINDSAY LOHAN', 'LISA KUDROW', 'LIZA MINELLI', 'LUCY LIU',\n",
       "        'MADONNA', 'MAHATMA GANDHI', 'MARGARET THATCHER', 'MARIAH CAREY',\n",
       "        'MARILYN MONROE', 'MARTHA STEWART', 'MARTIN LUTHER KING JR',\n",
       "        'MATT DAMON', 'MATTHEW PERRY', 'MEG RYAN', 'MEL GIBSON',\n",
       "        'MERYL STREEP', 'MICHAEL DOUGLAS', 'MICHAEL JACKSON',\n",
       "        'MICHAEL JORDAN', 'MICHAEL MOORE', 'MICK JAGGER', 'MIKE MYERS',\n",
       "        'MIKE TYSON', 'MORGAN FREEMAN', 'MR. T', 'MUHAMMAD ALI',\n",
       "        'NAPOLEON', 'NELSON MANDELA', 'NEWT GINGRICH', 'NICOLAS CAGE',\n",
       "        'NICOLE KIDMAN', 'NORMAN SCHWARZKOPF', 'OPRAH WINFREY',\n",
       "        'ORLANDO BLOOM', 'OWEN WILSON', 'PARIS HILTON', 'PETER JENNINGS',\n",
       "        \"PETER O'TOOLE\", 'PIERCE BROSNAN', 'PRINCE CHARLES',\n",
       "        'PRINCE WILLIAM', 'PRINCESS DIANA', 'PRINCE', 'QUEEN ELIZABETH',\n",
       "        'QUEEN LATIFAH', 'RALPH NADER', 'RAY CHARLES', 'REESE WITHERSPOON',\n",
       "        'REGIS PHILBIN', 'RENEE ZELLWEGER', 'RICHARD NIXON',\n",
       "        'RICHARD SIMMONS', 'RICKY MARTIN', 'ROBERT DENIRO',\n",
       "        'ROBERT REDFORD', 'ROBERTO BENIGNI', 'ROBIN WILLIAMS',\n",
       "        'RODNEY DANGERFIELD', 'RONALD REAGAN', 'ROSEANNE BARR',\n",
       "        'RUSSELL CROWE', 'SAM WATERSTON', 'SAMUEL L JACKSON',\n",
       "        'SARAH JESSICA PARKER', 'SCARLETT JOHANSSON', 'SEAN COMBS',\n",
       "        'SEAN PENN', \"SHAQUILLE O'NEAL\", 'SIMON COWELL', 'SNOOP DOGG',\n",
       "        'STEPHEN COLBERT', 'STEVE MARTIN', 'STEVEN SPIELBERG', 'STING',\n",
       "        'SUSAN SARANDON', 'SYLVESTER STALLONE', 'TERRELL OWENS',\n",
       "        'TIGER WOODS', 'TINA TURNER', 'TOBEY MAGUIRE', 'TOM BROKAW',\n",
       "        'TOM CRUISE', 'TOM HANKS', 'TONY BLAIR', 'UMA THURMAN', 'USHER',\n",
       "        'VIN DIESEL', 'VINCE VAUGHN', 'WAYNE GRETZKY', 'WHITNEY HOUSTON',\n",
       "        'WILL FERRELL', 'WILL SMITH', 'WINSTON CHURCHILL', 'WOLF BLITZER',\n",
       "        'ABU SIMBEL', 'ACADIA PARK', 'ACROPOLIS', 'AGRA FORT', 'ALAMO',\n",
       "        'ALCATRAZ', 'AMAZON RIVER', 'ANGEL FALLS', 'ANGKOR WAT',\n",
       "        'ARABIAN TOWER', 'ARC DE TRIOMPHE', 'ARUBA', 'ATLANTIC CITY',\n",
       "        'ATOMIUM', 'AYERS ROCK', 'BARCELONA CATHEDRAL', 'BAVARIAN CASTLE',\n",
       "        'BELLAGIO FOUNTAINS', 'BIG BEN', 'BLUE MOSQUE', 'BOSTON COMMON',\n",
       "        'BOURBON STREET', 'BRANDENBURG GATE', 'BRITISH MUSEUM',\n",
       "        'BROOKLYN BRIDGE', 'BRYCE CANYON', 'BUCKINGHAM FOUNTAIN',\n",
       "        'BUCKINGHAM PALACE', 'BUNKER HILL', 'CAMDEN YARDS', 'CANCUN',\n",
       "        'CAPE CANAVERAL', 'CAPE HORN', 'CAPE OF GOOD HOPE',\n",
       "        'CAPILANO BRIDGE', 'CAPITOL HILL', 'CARLSBAD CAVERNS',\n",
       "        'CARNEGIE HALL', 'CENTRAL PARK', 'CHARTRES CATHEDRAL',\n",
       "        'CHATEAU CHAMBORD', 'CHICAGO', 'CHRYSLER BUILDING',\n",
       "        'CHURCHILL DOWNS', 'CINDERELLA CASTLE', 'CLIFF PALACE', 'CN TOWER',\n",
       "        'COLOGNE CATHEDRAL', 'COLONIAL WILLIAMSBURG', 'COLOSSEUM',\n",
       "        'CORCOVADO', 'COVENT GARDEN', 'DEAD SEA', 'DEATH VALLEY', 'DELPHI',\n",
       "        \"DEVIL'S TOWER\", 'DOME OF THE ROCK', 'EASTER ISLAND',\n",
       "        'EIFFEL TOWER', 'EMPIRE STATE BUILDING', 'EPCOT CENTER',\n",
       "        'ETHIOPIAN CHURCH', 'EVERGLADES', 'FENWAY PARK',\n",
       "        \"FISHERMAN'S WHARF\", 'FLORENCE', 'FORBIDDEN CITY',\n",
       "        'GALAPAGOS ISLANDS', 'GATEWAY ARCH', 'GEORGE WASHINGTON BRIDGE',\n",
       "        'GETTYSBURG', \"GIANT'S CAUSEWAY\", 'GIZA PYRAMIDS',\n",
       "        'GLACIER NATIONAL PARK', 'GLOBE THEATER', 'GOLDEN GATE BRIDGE',\n",
       "        'GRACELAND', 'GRAND CANYON', 'GRAND CENTRAL STATION',\n",
       "        'GRAND OLE OPRY', 'GRAND TETON PARK', 'GREAT BARRIER REEF',\n",
       "        'GREAT SALT LAKE', 'GREAT WALL OF CHINA', 'GREAT ZIMBABWE RUINS',\n",
       "        'GUGGENHEIM', 'HARRODS', 'HAYDEN PLANETARIUM', 'HOLLYWOOD',\n",
       "        'HONG KONG', 'HOOVER DAM', 'HUNGARIAN PARLIAMENT', 'IGUAZU FALLS',\n",
       "        'INDEPENDENCE HALL', 'INDIANAPOLIS MOTOR SPEEDWAY',\n",
       "        'IWO JIMA MEMORIAL', 'JEFFERSON MEMORIAL', 'JENNE MOSQUE',\n",
       "        'JOHN HANCOCK CENTER', 'KAUFMAN STADIUM', 'KENSINGTON PALACE',\n",
       "        'KITTY HAWK BEACH', 'KOREAN WAR MEMORIAL', 'KREMLIN',\n",
       "        'KRONBORG CASTLE', 'KYOTO', 'LAKE TAHOE', 'LENIN MAUSOLEUM',\n",
       "        'LES INVALIDES', 'LIBERTY PLACE', 'LIBRARY OF CONGRESS',\n",
       "        'LINCOLN CENTER', 'LINCOLN FINANCIAL FIELD', 'LINCOLN MEMORIAL',\n",
       "        'LONDON DUNGEON', 'LONDON EYE', 'LOUVRE', 'LUXEMBOURG PALACE',\n",
       "        'LUXOR HOTEL', 'MACHU PICHU', 'MADISON SQUARE GARDEN',\n",
       "        'MALL OF AMERICA', 'MAMMOTH CAVE', 'MASADA',\n",
       "        'MASSACHUSETS STATE HOUSE', 'MAYAN PYRAMID', 'MECCA',\n",
       "        'METLIFE BUILDING', 'MGM GRAND', 'MILLENIUM PARK',\n",
       "        'MISSISSIPPI RIVER', 'MONTE CARLO', 'MONTEGO BAY', 'MONTICELLO',\n",
       "        'MONTMARTRE', 'MOULIN ROUGE', 'MOUNT BLANC', 'MOUNT EVEREST',\n",
       "        'MOUNT FUJI', 'MOUNT KILIMANJARO', 'MOUNT RAINIER',\n",
       "        'MOUNT ST HELENS', 'MOUNT VESUVIUS', 'NAPA VALLEY',\n",
       "        'NATIONAL AQUARIUM', 'NAVAL ACADEMY CHAPEL', 'NEWGRANGE',\n",
       "        'NIAGARA FALLS', 'NORTH POLE', 'NOTRE DAME', 'OAHU BEACH',\n",
       "        'OLD FAITHFUL', 'OLD STATE HOUSE', 'OLYMPIA', 'OXFORD',\n",
       "        'PACIFIC BELL PARK', 'PANAMA CANAL', 'PANTHEON', 'PARIS OPERA',\n",
       "        'PARK AVENUE', 'PEARL HARBOR', 'PENTAGON', 'PETRA',\n",
       "        'PETRIFIED FOREST', 'PETRONAS TOWERS', 'PHILADELPHIA ART MUSEUM',\n",
       "        'PHILADELPHIA CITY HALL', 'PICADILLY CIRCUS',\n",
       "        'PLACE DE LA CONCORDE', 'PLYMOUTH PLANTATION', 'POMPEI',\n",
       "        'PONT DU GARD', 'PRADO MUSEUM', 'PRAGUE', 'QUEBEC',\n",
       "        'QUINCY MARKET', 'REDWOOD FOREST', 'RIO DE JANEIRO',\n",
       "        'ROCK AND ROLL HALL OF FAME', 'ROCK OF GIBRALTAR',\n",
       "        'ROCKEFELLER CENTER', 'ROMAN FORUM', 'ROSE BOWL',\n",
       "        'ROYAL ALBERT HALL', 'SAHARA', 'SALT FLATS', 'SALT LAKE TEMPLE',\n",
       "        'SAN ANDREAS', 'SAN FRANCISCO', 'SEA WORLD', 'SEARS TOWER',\n",
       "        'SERENGETI PLAIN', 'SEVEN MILE BRIDGE', 'SHANGHAI', 'SHEA STADIUM',\n",
       "        'SIENA', 'SIERRA NEVADA', 'SISTINE CHAPEL', 'SKYDOME',\n",
       "        'SMITHSONIAN CASTLE', 'SMOKY MOUNTAINS', 'SOHO', 'SORBONNE CHAPEL',\n",
       "        'SPACE NEEDLE', 'SPHINX', 'ST BASILS CATHEDRAL',\n",
       "        'ST MARKS BASILICA', 'ST PATRICKS CATHEDRAL', 'ST PAULS CATHEDRAL',\n",
       "        'STATUE OF LIBERTY', 'STONEHENGE', 'SUEZ CANAL', 'SUPERDOME',\n",
       "        'SUPREME COURT', 'SYDNEY OPERA HOUSE', 'TABLE MOUNTAIN', 'TAHITI',\n",
       "        'TAJ MAHAL', 'THE MET', 'THE VENETIAN', 'TIMBUKTU', 'TIMES SQUARE',\n",
       "        'TOKYO', 'TOWER BRIDGE', 'TOWER OF LONDON', 'TOWER OF PISA',\n",
       "        'TRAFALGAR SQUARE', 'TREVI FOUNTAIN', 'TRITON FOUNTAIN',\n",
       "        'UNITED NATIONS BUILDING', 'VATICAN CITY', 'VENICE',\n",
       "        'VERRAZANO NARROWS', 'VERSAILLES', 'VIA APPIA', 'VICTORIA FALLS',\n",
       "        'VIENNA', 'VIETNAM MEMORIAL', 'WAILING WALL', 'WALK OF FAME',\n",
       "        'WALL STREET', 'WASHINGTON MONUMENT', 'WASHINGTON SQUARE ARCH',\n",
       "        'WESTMINSTER ABBEY', 'WHITE CLIFFS OF DOVER', 'WHITE HOUSE',\n",
       "        'WIMBLEDON', 'WINTER PALACE', 'WOOLWORTH BUILDING',\n",
       "        'WORLD WAR II MEMORIAL', 'WRIGLEY BUILDING', 'WRIGLEY FIELD',\n",
       "        'YANKEE STADIUM', 'YELLOWSTONE', 'YOSEMITE', 'YUKON RIVER',\n",
       "        'ACORN', 'ALLENWRENCH', 'ANCHOR', 'APPLE', 'APRON', 'ARMCHAIR',\n",
       "        'AXE', 'BABY BIB', 'BACKPACK', 'BALLOON', 'BANANA', 'BANDAID',\n",
       "        'BANJO', 'BANNER', 'BARBED WIRE', 'BARCODE SCANNER',\n",
       "        'BASEBALL BAT', 'BASKETBALL HOOP', 'BASKET', 'BAYONET', 'BED',\n",
       "        'BELL', 'BELT', 'BICYCLE', 'BIRDHOUSE', 'BLENDER', 'BLOWDRYER',\n",
       "        'BOLT', 'BOOK', 'BOTTLE', 'BOUQUET', 'BOWLING BALL', 'BOWL', 'BOX',\n",
       "        'BRICK', 'BROOM', 'BRUSH', 'BUCKET', 'BUGLE', 'BUTTON', 'CACTUS',\n",
       "        'CALCULATOR', 'CALENDAR', 'CAMERA', 'CANDLE', 'CANOE', 'CAR SEAT',\n",
       "        'CD', 'CHAIN', 'CHAIR', 'CIGARETTE', 'COLANDER', 'CORD', 'COUCH',\n",
       "        'CRADLE', 'CRAYONS', 'CROWN', 'CUP', 'CURTAIN', 'DEODORANT',\n",
       "        'DESK', 'DICE', 'DOLLAR', 'DOORKNOB', 'DOOR', 'DRESSER', 'DRILL',\n",
       "        'DRUM', 'EARRINGS', 'EASEL', 'EMERALD', 'FAUCET', 'FEATHER',\n",
       "        'FIRE EXTINGUISHER', 'FIREPLACE', 'FLASK', 'FLOWERPOT', 'FLOWER',\n",
       "        'FOAM CUP', 'FOOTBALL', 'FRIDGE', 'GARLIC', 'GAS MASK', 'GLASSES',\n",
       "        'GLASS', 'GLOBE', 'GLOVES', 'GLUE STICK', 'GOBLET', 'GOLF CLUB',\n",
       "        'GRILL', 'GUITAR', 'GUM', 'HAMMER', 'HANDCUFFS', 'HANDLE',\n",
       "        'HANGER', 'HAT', 'HELMET', 'HIGH CHAIR', 'HIGHLIGHTER', 'HURDLE',\n",
       "        'ICE', 'INHALER', 'INK CARTRIDGE', 'INTERCOM', 'IPOD', 'JACKET',\n",
       "        'JACKHAMMER', 'JEANS', 'JOYSTICK', 'KETCHUP', 'KEYBOARD',\n",
       "        'KEYCHAIN', 'KEYS', 'KLEENEX', 'KNIFE', 'LADDER', 'LADLE', 'LAMP',\n",
       "        'LANTERN', 'LAPTOP', 'LAWN MOWER', 'LEAF', 'LEGO', 'LEMON', 'LENS',\n",
       "        'LIGHT SWITCH', 'LIGHTBULB', 'LIGHTER', 'LIPSTICK', 'MAGNET',\n",
       "        'MAILBOX', 'MASCARA', 'MASK', 'MAYONNAISE', 'MEDAL', 'MICROCHIP',\n",
       "        'MICROPHONE', 'MICROSCOPE', 'MIRROR', 'MITTEN', 'MODEM', 'MOP',\n",
       "        'MOUSETRAP', 'MOUSE', 'NECKLACE', 'NEST', 'NEWSPAPER', 'ORANGE',\n",
       "        'PADLOCK', 'PAPER BAG', 'PAPER CLIP', 'PEDAL', 'PENCIL SHARPENER',\n",
       "        'PENDULUM', 'PEN', 'PEPPER', 'PERFUME', 'PETRI DISH', 'PHONE',\n",
       "        'PIANO', 'PIE', 'PILLOW', 'PILL', 'PIN', 'PLATE', 'PRINTER',\n",
       "        'PROJECTOR', 'PUMPKIN', 'PURSE', 'QUARTER', 'RACKET', 'RAKE',\n",
       "        'RAZOR', 'RECORD', 'REMOTE', 'RIBBON', 'RING', 'ROLLER SKATES',\n",
       "        'ROPE', 'ROSE', 'SADDLE', 'SAFE', 'SATELLITE DISH', 'SAUCEPAN',\n",
       "        'SCALE', 'SCARF', 'SCISSORS', 'SCREWDRIVER', 'SEASHELL', 'SHAMPOO',\n",
       "        'SHELF', 'SHIRT', 'SHOE', 'SHOVEL', 'SHOWER HEAD', 'SINK',\n",
       "        'SKATEBOARD', 'SLIPPERS', 'SMART CAR', 'SOAP', 'SOCKET', 'SOCK',\n",
       "        'SPEAKER', 'SPORK', 'SPRAY PAINT', 'STAMP', 'STAPLE REMOVER',\n",
       "        'STEERING WHEEL', 'STOCKING', 'STONE', 'STOP SIGN', 'STOVE',\n",
       "        'SURGE PROTECTOR', 'SWORD', 'SYRINGE', 'TABLE', 'TANKTOP',\n",
       "        'TEAPOT', 'TENT', 'THERMOMETER', 'THERMOS', 'TILE', 'TIRE',\n",
       "        'TOASTER', 'TOILET PAPER', 'TOILET SEAT', 'TOMATO', 'TOOTHPASTE',\n",
       "        'TOWEL', 'TRASH CAN', 'TRIPOD', 'TROPHY', 'TV', 'TWEEZERS',\n",
       "        'UKELELE', 'UMBRELLA', 'URINAL', 'VACUUM CLEANER', 'VASE', 'VEST',\n",
       "        'VIOLIN', 'WAFFLE', 'WALKMAN', 'WALLET', 'WATCH', 'WATER GUN',\n",
       "        'WEDDING DRESS', 'WHEEL', 'WHIP', 'WHISTLE', 'WINDOW', 'WREATH',\n",
       "        'YARN', 'ZIPLOCK BAG'], dtype=object),\n",
       " 'vector': {'loc': array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 1., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 1., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 1.]])}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) Grab studied items\n",
    "study = data.query(\"trial_type == 'study'\")\n",
    "items = study.groupby('item_index')['item'].first().to_numpy()      # List of all the study items, based on their item index\n",
    "patterns = {'items': items, 'vector': {'loc': loc_patterns}}        # List of items and patterns they correspond to\n",
    "patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters\n",
    "* What is the difference between a sublayer and a segment of the `f` and `c` layers?\n",
    "* What does the `w_loc` parameter do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed:\n",
      "\n",
      "\n",
      "free:\n",
      "\n",
      "\n",
      "dependent:\n",
      "\n",
      "\n",
      "dynamic:\n",
      "\n",
      "\n",
      "sublayers:\n",
      "f: ['task']\n",
      "c: ['task']\n",
      "\n",
      "weights:\n",
      "fc: {(('task', 'item'), ('task', 'item')): 'w_loc * loc'}\n",
      "cf: {(('task', 'item'), ('task', 'item')): 'w_loc * loc'}\n",
      "\n",
      "sublayer_param:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## (4) Define Parameters\n",
    "param_def = cmr.CMRParameters()\n",
    "\n",
    "param_def.set_sublayers(f=['task'], c=['task'])\n",
    "\n",
    "# weight format\n",
    "## tuple of tuples: ( (feature_sublayer, feature_segment),  (context_sublayer, context_segment)     :   'expression for weights')\n",
    "weights = {(('task', 'item'), ('task', 'item')): 'w_loc * loc'}\n",
    "\n",
    "param_def.set_weights(connect='fc', regions=weights)\n",
    "\n",
    "param_def.set_weights(connect='cf', regions=weights)\n",
    "\n",
    "print(param_def)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set the weights so that each feature neuron is only connected to the one context neuron with a weight of one \n",
    "* This is because `w_loc` = 1, `loc` = identity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of parameters\n",
    "param = {\n",
    "    'B_enc': 0.7,\n",
    "    'B_start': 0.3,\n",
    "    'B_rec': 0.9,\n",
    "    'w_loc': 1,\n",
    "    'Lfc': 0.15,\n",
    "    'Lcf': 0.15,\n",
    "    'P1': 0.2,\n",
    "    'P2': 2,\n",
    "    'T': 0.1,\n",
    "    'X1': 0.001,\n",
    "    'X2': 0.25\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluting a model using log likelihood\n",
    "* Log likelihood is the logarithm of the generated probability of a particular participant's recall sequence \n",
    "* The largest log likehood a recall sequence can have is 0 (log(1) = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logl</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-954.986639</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1112.451759</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-983.992163</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1273.049983</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-867.828568</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1109.605775</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-738.307772</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1114.587857</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1040.643977</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-995.241023</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1113.065378</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1130.671087</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-826.328607</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1140.602369</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1056.001668</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-1122.589020</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-1400.183793</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-968.290252</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-974.253140</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-1205.225185</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-689.372757</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-976.136409</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-876.523424</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-1070.923823</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-833.074904</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-1205.224047</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-962.152244</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-1020.814653</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-1109.104252</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                logl    n\n",
       "subject                  \n",
       "1        -954.986639  373\n",
       "2       -1112.451759  426\n",
       "3        -983.992163  379\n",
       "5       -1273.049983  517\n",
       "8        -867.828568  320\n",
       "11      -1109.605775  412\n",
       "16       -738.307772  297\n",
       "18      -1114.587857  403\n",
       "22      -1040.643977  378\n",
       "23       -995.241023  385\n",
       "24      -1113.065378  416\n",
       "25      -1130.671087  368\n",
       "27       -826.328607  279\n",
       "28      -1140.602369  449\n",
       "29      -1056.001668  407\n",
       "31      -1122.589020  459\n",
       "32      -1400.183793  568\n",
       "33       -968.290252  374\n",
       "34       -974.253140  322\n",
       "35      -1205.225185  461\n",
       "37       -689.372757  239\n",
       "38       -976.136409  432\n",
       "40       -876.523424  319\n",
       "41      -1070.923823  419\n",
       "42       -833.074904  311\n",
       "43      -1205.224047  428\n",
       "44       -962.152244  352\n",
       "45      -1020.814653  374\n",
       "46      -1109.104252  430"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cmr.CMR()\n",
    "\n",
    "results = model.likelihood(data, param, param_def=param_def, patterns=patterns)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Our Data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>position</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>item</th>\n",
       "      <th>item_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>study</td>\n",
       "      <td>Smaller and larger abscesses may require diffe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  list  position trial_type  \\\n",
       "0        0     0         1      study   \n",
       "\n",
       "                                                item  item_index  \n",
       "0  Smaller and larger abscesses may require diffe...           0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) Load in Data\n",
    "our_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) Associate each studied item with a pattern in the network \n",
    "import numpy as np\n",
    "\n",
    "n_items = our_data.item_index.max() + 1\n",
    "print(n_items)       \n",
    "loc_patterns = np.eye(n_items)\n",
    "loc_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': array(['Smaller and larger abscesses may require different methods for treatment.',\n",
       "        'Smaller abscesses are typically less than five millimeters wide.',\n",
       "        'Applying warm soaks can promote pus straining in smaller abscesses.',\n",
       "        'Larger abscesses will require an incision to strain them.',\n",
       "        'Signs of larger abscesses include increased inflammation and pus collection.',\n",
       "        'Ensure the appropriate precautions are met before treating the patient.',\n",
       "        'Gather all necessary equipment required to care for the abscess.',\n",
       "        'Position the patient so the abscess is easily accessible.',\n",
       "        'Surround the abscess with cleaned drapes and cover adjacent areas.',\n",
       "        'Lastly, apply anesthesia to the edge surrounding the abscess.',\n",
       "        'Once required preparations are complete, perform the incision and strainage.',\n",
       "        'Insert the syringe slightly under the skin to inject anesthetic.',\n",
       "        'Next, cut open the abscess and strain out all pus.',\n",
       "        'Apply gauze to soak up any excess pus or blood.',\n",
       "        'Use caution, for abscesses could contain sharp or jagged objects.',\n",
       "        'Record information about the abscess and procedure on SF 600.',\n",
       "        'Describe details about the abscess prior to completing the procedure.',\n",
       "        'Recount the procedure used, such as the quantity of anesthesia.',\n",
       "        'Provide details on how the patient tolerated the procedure.',\n",
       "        'Include any follow up care instructions given to the patient.',\n",
       "        'To begin, determine cause and severity of casualty burns.',\n",
       "        'Determine if they were exposed to smoke, steam, or combustion products.',\n",
       "        'Possible causes include open flame, hot liquid, chemicals, or electricity.',\n",
       "        'Explosions and lightning may cause burn and additional injury.',\n",
       "        'These injuries may include internal injury, fracture, or spinal injury.',\n",
       "        'Now you must prepare to stop the burn process.',\n",
       "        'For thermal burns, the patient must stop, drop, and roll.',\n",
       "        'If the cause is electrical, turn off the electrical current.',\n",
       "        'Victims of lightning strikes may need prolonged respiratory support.',\n",
       "        'For chemical burns, flush the area of contact with water immediately.',\n",
       "        'Once the burn process is stopped, begin to treat the patient.',\n",
       "        'Unblock the airway and check for signs of inhalation.',\n",
       "        'Signs include singed eyebrows and eyelashes, hoarseness, and loud inhalation.',\n",
       "        'Another sign is presence of carbon discoloration in the mouth.',\n",
       "        'Oxygen must now be administered to patient at a high flow rate.',\n",
       "        'Determine percentage of body surface area burnt and burn degree.',\n",
       "        'The percentage is calculated with the rule of nines.',\n",
       "        'The head and neck account for 9% of surface area.',\n",
       "        'The upper limbs host 18% of surface area (each 9%).',\n",
       "        'The lower limbs carry 36% of surface area (each 18%).',\n",
       "        'There are two methods for locating foreign bodies in eyes.',\n",
       "        'For method one, pull the eyelid away from the eyeball.',\n",
       "        'Place a cotton swab along the back of the lid.',\n",
       "        \"Fold the patient's eyelid backward over the cotton swab.\",\n",
       "        'Look for any foreign bodies or damage to the eyeball.',\n",
       "        'The second method for locating foreign bodies is as follows.',\n",
       "        'Pull the lower lid down or the upper lid up.',\n",
       "        'Have the patient look up, down, and to both sides.',\n",
       "        'Check for objects in the eye as they look around.',\n",
       "        'If nothing is found, bandage both eyes and seek help.',\n",
       "        'The next step is to remove the foreign object.',\n",
       "        'Hold the eye open or pull the eyelid away.',\n",
       "        'For small foreign bodies, irrigate it out of the eye.',\n",
       "        'Remove the body with a sterile cotton swab if stuck.',\n",
       "        'If there is pain, bandage both eyes and seek aid.',\n",
       "        'If the foreign body penetrates the eye, do the following.',\n",
       "        'Apply dry sterile dressings to support the foreign body.',\n",
       "        'Cover both the injured and uninjured eyes to minimize movement.',\n",
       "        'Completing this step also prevents further contamination of the eye.',\n",
       "        'Once these steps are complete, seek further medical aid immediately.',\n",
       "        'Begin preparing for assessment and treatment of head wounds.',\n",
       "        'Ensure you have necessary equipment, such as dressings and cravats.',\n",
       "        'Secure a safe environment, clear of any close dangers.',\n",
       "        'Prevent additional sicknesses by completing a patient care hand wash.',\n",
       "        'Check the patient for signs and symptoms of head wounds.',\n",
       "        'One type of head wound is a closed head injury.',\n",
       "        'These are caused by a hard impact to the head.',\n",
       "        'One symptom of this injury is deformity of the head.',\n",
       "        'Symptoms of closed head injuries also include elevated body temperatures.',\n",
       "        'Insufficient oxygen to the brain results in feelings of restlessness.',\n",
       "        'The other type of wound is an open head injury.',\n",
       "        'This includes penetrating entry wounds, with no exit wounds.',\n",
       "        'Symptoms also involve paralysis to one side of the body.',\n",
       "        'Open head injuries may also look like mangled scalp tissue.',\n",
       "        'This kind of wound may result in extensive bleeding.',\n",
       "        \"Assess the patient's level of consciousness by the following assessments.\",\n",
       "        'The Glasgow Coma Scale looks at verbal and motor responses.',\n",
       "        \"It also checks if the patient's eyes are opening properly.\",\n",
       "        'For the AVPU scale, check if the patient is unresponsive.',\n",
       "        'Ask the patient for the date, time, and their name.'],\n",
       "       dtype=object),\n",
       " 'vector': {'loc': array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 1., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 1., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 1.]])}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) Associate each sentence with a pattern\n",
    "items = our_data.groupby('item_index')['item'].first().to_numpy()      # List of all the study items, based on their item index\n",
    "patterns = {'items': items, 'vector': {'loc': loc_patterns}}        # List of items and patterns they correspond to\n",
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed:\n",
      "\n",
      "\n",
      "free:\n",
      "\n",
      "\n",
      "dependent:\n",
      "\n",
      "\n",
      "dynamic:\n",
      "\n",
      "\n",
      "sublayers:\n",
      "f: ['task']\n",
      "c: ['task']\n",
      "\n",
      "weights:\n",
      "fc: {(('task', 'item'), ('task', 'item')): 'w_loc * loc'}\n",
      "cf: {(('task', 'item'), ('task', 'item')): 'w_loc * loc'}\n",
      "\n",
      "sublayer_param:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## (4) Set Parameters\n",
    "param_def = cmr.CMRParameters()\n",
    "param_def.set_sublayers(f=['task'], c=['task'])\n",
    "weights = {(('task', 'item'), ('task', 'item')): 'w_loc * loc'}\n",
    "param_def.set_weights(connect='fc', regions=weights)\n",
    "param_def.set_weights(connect='cf', regions=weights)\n",
    "param = {'B_enc': 0.7, 'B_start': 0.3, 'B_rec': 0.9, 'w_loc': 1, 'Lfc': 0.15, 'Lcf': 0.15, 'P1': 0.2, 'P2': 2, 'T': 0.1, 'X1': 0.001, 'X2': 0.25\n",
    "}\n",
    "print(param_def)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logl</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-152.810677</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-128.119155</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-140.954833</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-175.773679</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-159.140012</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-148.126789</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-153.090002</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-152.429836</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-163.047069</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-137.881234</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-239.423485</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-159.419095</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-163.462700</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-156.569227</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-144.869244</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-152.564911</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-157.705654</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-148.939454</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               logl   n\n",
       "subject                \n",
       "0       -152.810677  43\n",
       "1       -128.119155  31\n",
       "2       -140.954833  35\n",
       "3       -175.773679  60\n",
       "4       -159.140012  43\n",
       "5       -148.126789  38\n",
       "6       -153.090002  37\n",
       "7       -152.429836  56\n",
       "8       -163.047069  52\n",
       "9       -137.881234  37\n",
       "10      -239.423485  74\n",
       "11      -159.419095  45\n",
       "12      -163.462700  62\n",
       "13      -156.569227  39\n",
       "14      -144.869244  39\n",
       "15      -152.564911  40\n",
       "16      -157.705654  52\n",
       "17      -148.939454  37"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (5) Use model to evaluate likelihood of free recall data\n",
    "model = cmr.CMR()\n",
    "results = model.likelihood(our_data, param, param_def=param_def, patterns=patterns)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the participants whose recalls had super low probabilities for their recall sequence (as there might be an error in scoring)\n",
    "* AL1005 \n",
    "* AL1013 \n",
    "* AL1018 \n",
    "* AL1025 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Fitting a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CMR model is a neural network has three parts:\n",
    "1. One layer that encodes events, each neuron representing a feature of the event\n",
    "2. One layer that encodes contexts, each neuron representing a particular time or situation\n",
    "3. Weighted connections two layers, each connection tells us how much an event is tied to a context (particular time or situation )\n",
    "\n",
    "It also has three rules that govern its behavior:\n",
    "1. Context Reinstatement (`f_i -> c_i`) -- How remembering an event causes you to remember it's context \n",
    "2. Associations between Layers (`f_i, c_i -> M^FC`) -- How are events associated with contexts?  -- `Hebbian Learning Rule \"Neurons that fire together wire together\"`\n",
    "1. Retrieval Competion (`c_i -> f_i`) -- How context is used as a retrieval cue (an aid to remember events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>position</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>item</th>\n",
       "      <th>item_index</th>\n",
       "      <th>session</th>\n",
       "      <th>list_type</th>\n",
       "      <th>category</th>\n",
       "      <th>response</th>\n",
       "      <th>response_time</th>\n",
       "      <th>list_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>study</td>\n",
       "      <td>SEAN PENN</td>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "      <td>mixed</td>\n",
       "      <td>cel</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.255</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>study</td>\n",
       "      <td>AUDREY HEPBURN</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>mixed</td>\n",
       "      <td>cel</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.040</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>study</td>\n",
       "      <td>ST PATRICKS CATHEDRAL</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>mixed</td>\n",
       "      <td>loc</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.164</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>study</td>\n",
       "      <td>LES INVALIDES</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>mixed</td>\n",
       "      <td>loc</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.829</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>study</td>\n",
       "      <td>GREAT ZIMBABWE RUINS</td>\n",
       "      <td>340</td>\n",
       "      <td>1</td>\n",
       "      <td>mixed</td>\n",
       "      <td>loc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.872</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  list  position trial_type                   item  item_index  \\\n",
       "0        1     2         1      study              SEAN PENN         228   \n",
       "1        1     2         2      study         AUDREY HEPBURN          19   \n",
       "2        1     2         3      study  ST PATRICKS CATHEDRAL         463   \n",
       "3        1     2         4      study          LES INVALIDES         364   \n",
       "4        1     2         5      study   GREAT ZIMBABWE RUINS         340   \n",
       "\n",
       "   session list_type category  response  response_time list_category  \n",
       "0        1     mixed      cel       3.0          1.255         mixed  \n",
       "1        1     mixed      cel       3.0          1.040         mixed  \n",
       "2        1     mixed      loc       2.0          1.164         mixed  \n",
       "3        1     mixed      loc       2.0          0.829         mixed  \n",
       "4        1     mixed      loc       3.0          0.872         mixed  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (0) Load in free recall data -- this particular free recall study participants looked at pictures of people, places, and objects,\n",
    "from cymr import fit, cmr\n",
    "data = fit.sample_data('Morton2013_mixed')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CMR model is defined parameters (variables that control how the model behaves).\n",
    "* Beta_encoding = How much recalling an item changes the current context (contextual re-instatement)\n",
    "* Gamma () = Controls the degree of forward asymmetry\n",
    "* Phi = Controls primacy effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Define a set of Parameters for the Model along with pre-experimental weights\n",
    "par = cmr.CMRParameters()\n",
    "\n",
    "par.set_fixed(T=0.1, Lfc=0.15, Lcf=0.15, P1=0.2, P2=2,\n",
    "              B_start=0.3, B_rec=0.9, X1=0.001, X2=0.25)\n",
    "\n",
    "\n",
    "par.set_free(B_enc=(0, 1))\n",
    "\n",
    "par.set_dependent(Dfc='1 - Lfc', Dcf='1 - Lcf')\n",
    "\n",
    "n_items = 768\n",
    "\n",
    "study = data.query(\"trial_type == 'study'\")\n",
    "\n",
    "items = study.groupby('item_index')['item'].first().to_numpy()\n",
    "\n",
    "patterns = {'items': items, 'vector': {'loc': np.eye(n_items)}}\n",
    "\n",
    "par.set_sublayers(f=['task'], c=['task'])\n",
    "\n",
    "weights = {(('task', 'item'), ('task', 'item')): 'loc'}\n",
    "\n",
    "par.set_weights('fc', weights)\n",
    "\n",
    "par.set_weights('cf', weights)\n",
    "# We cans save a set of parameters into a JSON file\n",
    "# par.to_json('parameters.json')\n",
    "\n",
    "# restored = cmr.read_config('parameters.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rep</th>\n",
       "      <th>T</th>\n",
       "      <th>Lfc</th>\n",
       "      <th>Lcf</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>B_start</th>\n",
       "      <th>B_rec</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>B_enc</th>\n",
       "      <th>Dfc</th>\n",
       "      <th>Dcf</th>\n",
       "      <th>logl</th>\n",
       "      <th>n</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.693528</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-954.976072</td>\n",
       "      <td>373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.615342</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1109.066717</td>\n",
       "      <td>426</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.743079</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-983.635155</td>\n",
       "      <td>379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.577965</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1264.186512</td>\n",
       "      <td>517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.627175</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-866.701444</td>\n",
       "      <td>320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rep    T   Lfc   Lcf   P1   P2  B_start  B_rec     X1    X2  \\\n",
       "subject                                                                \n",
       "1          0  0.1  0.15  0.15  0.2  2.0      0.3    0.9  0.001  0.25   \n",
       "2          0  0.1  0.15  0.15  0.2  2.0      0.3    0.9  0.001  0.25   \n",
       "3          0  0.1  0.15  0.15  0.2  2.0      0.3    0.9  0.001  0.25   \n",
       "5          0  0.1  0.15  0.15  0.2  2.0      0.3    0.9  0.001  0.25   \n",
       "8          0  0.1  0.15  0.15  0.2  2.0      0.3    0.9  0.001  0.25   \n",
       "\n",
       "            B_enc   Dfc   Dcf         logl    n  k  \n",
       "subject                                             \n",
       "1        0.693528  0.85  0.85  -954.976072  373  1  \n",
       "2        0.615342  0.85  0.85 -1109.066717  426  1  \n",
       "3        0.743079  0.85  0.85  -983.635155  379  1  \n",
       "5        0.577965  0.85  0.85 -1264.186512  517  1  \n",
       "8        0.627175  0.85  0.85  -866.701444  320  1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2) Create Model using Parameters\n",
    "model = cmr.CMR()\n",
    "results = model.fit_indiv(data, par, patterns=patterns, tol=0.1)\n",
    "best = fit.get_best_results(results)\n",
    "\n",
    "# logl = logarithm of the probability of the participant's recall sequence according to the model\n",
    "# k = number of free parameters\n",
    "# best[['B_enc', 'logl', 'n', 'k']].head(5)\n",
    "best.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Our Data:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the parameters of the model, and see which one we might want to search for or set:\n",
    "\n",
    "**Search For:**\n",
    "* `Lfc` and `Lcf`:  learning rate for the weights between layers   (0 - 1)\n",
    "* `B_enc`:    integration rate during studying      (0 - 1)\n",
    "* `B_start` : integration rate at the start of remembering  (0 - 1)\n",
    "* `B_rec`:    integration rate during recall    (0 - 1)\n",
    "* `P1`:       Additional context item strength for first item  (0 - 1)\n",
    "* `P2`:       Decay weight for primacy learning gradient (??)\n",
    "* `X2`:       Determines exponential function that describes probability of stopping by output position (0 - 1)\n",
    "  * Smaller value, more people remember\n",
    "\n",
    "**Set:**\n",
    "* `X1`: probability of not recalling any items (can manually calculate this when we include phone calls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Parameters**\n",
    "\n",
    "* Learning: Learning Rates (Lfc and Lcf), Primacy effect parameters (P1 and P2)\n",
    "\n",
    "* Integration: How much the activity in `f` layer integrated into `c` layer (B_enc, B_start, B_rec)\n",
    "\n",
    "* End of Recall: X1 and X2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameter Defintion Object:** is used to manage parameters. It defines the structure of the network (weight and sublayers and segments), and along ranges of acceptable parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (0) Calculate the probability of not remembering anything\n",
    "our_data.head()\n",
    "groupby_columns = [\"subject\", \"list\"]\n",
    "num_empty_recalls = 0 \n",
    "for trial_index, trial in enumerate(our_data.groupby(groupby_columns)):\n",
    "    trial = trial[1]\n",
    "    if len(trial) ==  trial.trial_type.value_counts()[\"study\"]:    # IF participant does not recall anything\n",
    "        num_empty_recalls += 1\n",
    "\n",
    "prob_not_recalling_anything = num_empty_recalls / trial_index\n",
    "prob_not_recalling_anything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "## (1.1) Create a parameter object (represents the parameters of a CMR model)\n",
    "par = cmr.CMRParameters()\n",
    "par.set_fixed(T=0.1, X1=prob_not_recalling_anything)\n",
    "par.set_free(B_enc=(0.01, .999), \n",
    "             B_start=(0.01, .999), \n",
    "             B_rec=(0.01, .999), \n",
    "             X2=(0.01, .999), \n",
    "             Lfc=(0.01, .999), \n",
    "             Lcf=(0.01, .999),\n",
    "             P1=(0.01, .999),\n",
    "             P2=(0.5, 4))\n",
    "\n",
    "par.set_dependent(Dfc='1 - Lfc', Dcf='1 - Lcf')\n",
    "\n",
    "## (1.2) Grab all the studied items and associate them with a pattern in the model\n",
    "n_items = our_data.item_index.max() + 1\n",
    "loc_patterns = np.eye(n_items)\n",
    "items = our_data.groupby('item_index')['item'].first().to_numpy()      # List of all the study items, based on their item index\n",
    "patterns = {'items': items, 'vector': {'loc': loc_patterns}}        # List of items and patterns they correspond to\n",
    "\n",
    "# (1.3) Set up the weights connecting the two layers of the model\n",
    "par.set_sublayers(f=['task'], c=['task'])\n",
    "weights = {(('task', 'item'), ('task', 'item')): 'loc'}\n",
    "par.set_weights('fc', weights)\n",
    "par.set_weights('cf', weights)\n",
    "# print(par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[39m=\u001b[39m cmr\u001b[39m.\u001b[39mCMR()\n\u001b[0;32m      3\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit_indiv(our_data, par, patterns\u001b[39m=\u001b[39mpatterns, tol\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m, n_rep\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m best \u001b[39m=\u001b[39m fit\u001b[39m.\u001b[39mget_best_results(results)\n\u001b[0;32m      5\u001b[0m \u001b[39m# logl = logarithm of the probability of the participant's recall sequence according to the model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# k = number of free parameters\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# n = number of data points (tested before found acceptable fit)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m best\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "# (2) Create Model using Parameters\n",
    "model = cmr.CMR()\n",
    "results = model.fit_indiv(our_data, par, patterns=patterns, tol=0.05, n_rep=1)\n",
    "best = fit.get_best_results(results)\n",
    "# logl = logarithm of the probability of the participant's recall sequence according to the model\n",
    "# k = number of free parameters\n",
    "# n = number of data points (tested before found acceptable fit)\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trouble-shooting**\n",
    "It looks like the beta encoding rates are super small. Why is that? \n",
    "* Maybe it's because we don't have enough data to fit the model? To test this, let's combine all the free recall data into one participant.\n",
    "\n",
    "It was not because we didn't have enough data, but rather because we didn't search the parameter space and that caused the model to act super funky. \n",
    "* All the parameters work together to create the behavior of this model. If one parameter is significantly off for the model, that will push other parameters off to account for that gap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TROUBLE SHOOTING\n",
    "# (0) Combine all the recall data into one participant\n",
    "# test_enc_rate_df = our_data.copy()\n",
    "# num_passages_upper_bound = our_data.list.max() + 1\n",
    "# new_lst_index = [ (num_passages_upper_bound*subject) + lst for subject,lst in zip(our_data.subject, our_data.list)]\n",
    "# test_enc_rate_df[\"list\"] = new_lst_index        # Created a list index so there are no collisions\n",
    "# test_enc_rate_df[\"subject\"] = 0\n",
    "# test_enc_rate_df\n",
    "\n",
    "# from psifr import fr\n",
    "# crps = fr.lag_crp(fr.merge_free_recall(our_data))\n",
    "# fr.plot_lag_crp(crps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the parameters we found to generate free recall data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Generating Simulated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>position</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>item</th>\n",
       "      <th>item_index</th>\n",
       "      <th>session</th>\n",
       "      <th>list_type</th>\n",
       "      <th>category</th>\n",
       "      <th>response</th>\n",
       "      <th>response_time</th>\n",
       "      <th>list_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>study</td>\n",
       "      <td>SEAN PENN</td>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "      <td>mixed</td>\n",
       "      <td>cel</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.255</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>study</td>\n",
       "      <td>AUDREY HEPBURN</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>mixed</td>\n",
       "      <td>cel</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.040</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>study</td>\n",
       "      <td>ST PATRICKS CATHEDRAL</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>mixed</td>\n",
       "      <td>loc</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.164</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>study</td>\n",
       "      <td>LES INVALIDES</td>\n",
       "      <td>364</td>\n",
       "      <td>1</td>\n",
       "      <td>mixed</td>\n",
       "      <td>loc</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.829</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>study</td>\n",
       "      <td>GREAT ZIMBABWE RUINS</td>\n",
       "      <td>340</td>\n",
       "      <td>1</td>\n",
       "      <td>mixed</td>\n",
       "      <td>loc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.872</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>20</td>\n",
       "      <td>study</td>\n",
       "      <td>CHE GUEVARA</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>mixed</td>\n",
       "      <td>cel</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.641</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>21</td>\n",
       "      <td>study</td>\n",
       "      <td>OAHU BEACH</td>\n",
       "      <td>406</td>\n",
       "      <td>3</td>\n",
       "      <td>mixed</td>\n",
       "      <td>loc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.997</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>study</td>\n",
       "      <td>GATEWAY ARCH</td>\n",
       "      <td>324</td>\n",
       "      <td>3</td>\n",
       "      <td>mixed</td>\n",
       "      <td>loc</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.589</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>study</td>\n",
       "      <td>WHITE HOUSE</td>\n",
       "      <td>501</td>\n",
       "      <td>3</td>\n",
       "      <td>mixed</td>\n",
       "      <td>loc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.733</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>study</td>\n",
       "      <td>WRIGLEY BUILDING</td>\n",
       "      <td>506</td>\n",
       "      <td>3</td>\n",
       "      <td>mixed</td>\n",
       "      <td>loc</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.495</td>\n",
       "      <td>mixed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>720 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject  list  position trial_type                   item  item_index  \\\n",
       "0           1     2         1      study              SEAN PENN         228   \n",
       "1           1     2         2      study         AUDREY HEPBURN          19   \n",
       "2           1     2         3      study  ST PATRICKS CATHEDRAL         463   \n",
       "3           1     2         4      study          LES INVALIDES         364   \n",
       "4           1     2         5      study   GREAT ZIMBABWE RUINS         340   \n",
       "...       ...   ...       ...        ...                    ...         ...   \n",
       "1062        1    48        20      study            CHE GUEVARA          51   \n",
       "1063        1    48        21      study             OAHU BEACH         406   \n",
       "1064        1    48        22      study           GATEWAY ARCH         324   \n",
       "1065        1    48        23      study            WHITE HOUSE         501   \n",
       "1066        1    48        24      study       WRIGLEY BUILDING         506   \n",
       "\n",
       "      session list_type category  response  response_time list_category  \n",
       "0           1     mixed      cel       3.0          1.255         mixed  \n",
       "1           1     mixed      cel       3.0          1.040         mixed  \n",
       "2           1     mixed      loc       2.0          1.164         mixed  \n",
       "3           1     mixed      loc       2.0          0.829         mixed  \n",
       "4           1     mixed      loc       3.0          0.872         mixed  \n",
       "...       ...       ...      ...       ...            ...           ...  \n",
       "1062        3     mixed      cel       3.0          0.641         mixed  \n",
       "1063        3     mixed      loc       3.0          0.997         mixed  \n",
       "1064        3     mixed      loc       2.0          0.589         mixed  \n",
       "1065        3     mixed      loc       3.0          0.733         mixed  \n",
       "1066        3     mixed      loc       3.0          0.495         mixed  \n",
       "\n",
       "[720 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (0) Load in data\n",
    "from cymr import fit, cmr\n",
    "\n",
    "from psifr import fr\n",
    "\n",
    "data = fit.sample_data('Morton2013_mixed')\n",
    "\n",
    "items = (data\n",
    "    .query('trial_type == \"study\"')\n",
    "    .groupby('item_index')\n",
    "    .first()['item']\n",
    "    .to_numpy()\n",
    ")\n",
    "\n",
    "data = fr.filter_data(data, subjects=1)\n",
    "\n",
    "fr.filter_data(data, trial_type='study')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Define the parameters of our model\n",
    "param = {\n",
    "    'B_enc': 0.6,\n",
    "    'B_start': 0.3,\n",
    "    'B_rec': 0.8,\n",
    "    'Afc': 0,\n",
    "    'Dfc': 0.85,\n",
    "    'Acf': 1,\n",
    "    'Dcf': 0.85,\n",
    "    'Aff': 0,\n",
    "    'Dff': 1,\n",
    "    'Lfc': 0.15,\n",
    "    'Lcf': 0.15,\n",
    "    'P1': 0.8,\n",
    "    'P2': 1,\n",
    "    'T': 0.1,\n",
    "    'X1': 0.001,\n",
    "    'X2': 0.35\n",
    "}\n",
    "\n",
    "patterns = {'items': items, 'vector': {'loc': np.eye(768)}}\n",
    "\n",
    "param_def = cmr.CMRParameters()\n",
    "\n",
    "param_def.set_sublayers(f=['task'], c=['task'])\n",
    "\n",
    "weights = {(('task', 'item'), ('task', 'item')): 'loc'}\n",
    "\n",
    "param_def.set_weights('fc', weights)\n",
    "\n",
    "param_def.set_weights('cf', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>list</th>\n",
       "      <th>item</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>study</th>\n",
       "      <th>recall</th>\n",
       "      <th>repeat</th>\n",
       "      <th>intrusion</th>\n",
       "      <th>prior_list</th>\n",
       "      <th>prior_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SEAN PENN</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject  list       item  input  output  study  recall  repeat  intrusion  \\\n",
       "0        1     2  SEAN PENN      1    12.0   True    True       0      False   \n",
       "\n",
       "   prior_list  prior_input  \n",
       "0         NaN          NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  (2) Simulate free recall sessions using the model, and score them\n",
    "model = cmr.CMR()\n",
    "sim = model.generate(data, param, param_def=param_def, patterns=patterns, n_rep=5)\n",
    "sim.head(1)\n",
    "\n",
    "sim_data = fr.merge_free_recall(sim)\n",
    "sim_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASIAAAEnCAYAAAANc04FAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3OklEQVR4nO3deVhUZfsH8O8MzAz7JrIKghtqKiBb4JavGL4mSraYVqCVpimZlD/FFLJFzNLMpCxNbTPJEjXt1ZTEDRDZtQBRQFQcFpV9n3l+fyCTI4szOMMZ4P5c11yXc+Y559xzam6e82yHxxhjIIQQDvG5DoAQQigREUI4R4mIEMI5SkSEEM5RIiKEcI4SESGEc5SICCGco0RECOEcJSJCCOcoERFCOMdpIjp9+jT8/f1hY2MDHo+HAwcOPHSf2NhYjB49GiKRCIMGDcLu3bvVHichRL04TUTV1dVwdnZGZGSkQuXz8vLw1FNPYeLEiUhLS8Nbb72F1157DceOHVNzpIQQdeJpyqRXHo+H6OhoBAQEtFtmxYoVOHLkCC5duiTb9sILL6CsrAxHjx7tgigJIerQrdqI4uPj4evrK7fNz88P8fHx7e5TX1+PiooK2au8vBwlJSXQkPxLCEE3S0RisRiWlpZy2ywtLVFRUYHa2to294mIiICxsbHsZWJiAgsLC1RWVnZFyIT0OBF/ZGLHmVzcrqpX2TG7VSLqjNDQUJSXl8te169f5zokQrqtyrpG7DyXhw+PZKK8tlFlx9VW2ZG6gJWVFYqKiuS2FRUVwcjICLq6um3uIxKJIBKJuiI8Qnq805dL0ShhGGCujwF9DVR23G5VI/L29kZMTIzctuPHj8Pb25ujiAjpXWIymysCk4ZZqPS4nCaiqqoqpKWlIS0tDUBz93xaWhoKCgoANN9WBQYGysovXLgQubm5+L//+z9kZWXhyy+/xC+//IJly5ZxET4hvYpEynAyuxgAMGmY5UNKK4fTRJSUlARXV1e4uroCAEJCQuDq6oqwsDAAwK1bt2RJCQAcHR1x5MgRHD9+HM7Ozti4cSN27NgBPz8/TuInpDdJKbiLuzWNMNYVwL2/qUqPrTHjiLpKRUUFjI2NUV5eDiMjI67DIaTbiPhfJr4+lYsZLjb4/AVXlR67W7UREUK4E5OpntsygBIRIUQB+aXVuFJcBW0+DxOG9FX58SkREUIe6sS93jIPBzMY6wpUfnxKRISQh2q5LfMdrvrbMoASESHkIcprG3Eh/w4AwFfF44daUCIihHTo1OUSNEkZBlkYoH8ffbWcgxIRIaRD6hpNfT9KRISQdjVJpIjNLgEA+Kqh274FJSJCSLuSrt1FeW0jTPUEGG2v2tHU96NERAhpV8tt2UQnC2jxeWo7DyUiQki71Dma+n6UiAghbcotqUJuaTUEWjyMH2Ku1nNRIiKEtKmlNuTl2AeGOqofTX0/SkSEkDad6IJu+xaUiAghrZTVNCDp2l0A6u22b0GJiBDSSmx2CSRShiGWBrAz01P7+SgREUJa+fe2TP21IYASESHkAY0SKU5dbhlNrf72IYASESHkARfy7qCyrglm+kK42KlvNPX9KBERQuScuNdtr+7R1PejREQIkWGMISaruX1o8vCuuS0DKBERQu5ztaQK127XQKjFx7jBql+buj2UiAghMi23ZY8P7AN9Udc9kZ4SESFE5mxOKQDgP05dVxsCKBERQu5paJIi6Vrz2tQ+g9Q7yfVBlIgIIQCAjBtlqGuUwkxfiMEWBl16bkpEhBAAwPm85tqQl6MZeLyu6bZvQYmIEAIASMi9DQB4fECfLj83JSJCCBolUiTlN8+29xpg1uXnp0RECEHGjXLUNkpgqifAEAvDLj8/JSJCiOy2zMuxD/hdNK3jfpSICCH/JiIObssASkSE9HqNEimS763GyEVDNUCJiJBe7+LNctQ0SGCiJ4CTZde3DwEakIgiIyPh4OAAHR0deHl5ITExscPymzdvhpOTE3R1dWFnZ4dly5ahrq6ui6IlpOc5n9s8fsjTwYyT9iGA40QUFRWFkJAQhIeHIyUlBc7OzvDz80NxcXGb5ffs2YOVK1ciPDwcmZmZ+PbbbxEVFYVVq1Z1ceSE9Bxcjh9qwWki2rRpE+bPn4958+Zh+PDh2LZtG/T09LBz5842y8fFxWHMmDGYM2cOHBwc8OSTT2L27NkPrUURQtrWJJEiKb+5RtQrE1FDQwOSk5Ph6+v7bzB8Pnx9fREfH9/mPj4+PkhOTpYlntzcXPzxxx+YOnVqu+epr69HRUWF3IsQ0uxSYQWqGyQw1hVgqBU37UMA0HULjjygtLQUEokElpbyTwmwtLREVlZWm/vMmTMHpaWlGDt2LBhjaGpqwsKFCzu8NYuIiMDatWtVGjshPUXLbZmnI3ftQ4AGNFYrIzY2FuvWrcOXX36JlJQU7N+/H0eOHMEHH3zQ7j6hoaEoLy+Xva5fv96FEROi2TShfQjgsEZkbm4OLS0tFBUVyW0vKiqClZVVm/usWbMGL7/8Ml577TUAwMiRI1FdXY0FCxbg3XffBZ/fOq+KRCKIRCLVfwFCurmm++eXOXIzkLEFZzUioVAINzc3xMTEyLZJpVLExMTA29u7zX1qampaJRstLS0AzYt+d7WKukY0SqRdfl5CVOHvwgpU1TfBSEcbw6yNOI2FsxoRAISEhCAoKAju7u7w9PTE5s2bUV1djXnz5gEAAgMDYWtri4iICACAv78/Nm3aBFdXV3h5eeHKlStYs2YN/P39ZQmpq8RdLcVr3yXhMRsj7Fvo06XnJkQV/m0f6tNljw1qD6eJaNasWSgpKUFYWBjEYjFcXFxw9OhRWQN2QUGBXA1o9erV4PF4WL16NW7evIm+ffvC398fH330UZfGnXztLl77Lgk1DRJcyL+Lm2W1sDXR7dIYCHlULQuhPc7R/LL78RgX9zQcqqiogLGxMcrLy2FkpHx19NLNcszenoDKuibZto+fGYlZHvaqDJMQtZJIGVzW/onK+iYcDh6LEbbGnMbTrXrNuHaluBKBOxNRWdcEDwdTzB/nCAA4c+/JB4R0F/8UVqCyvgmGGtA+BFAiUti129WYs/087lQ3YFQ/Y3w71wN+jzX37p29UgqJtFdVLEk3J2sfcjDjvH0IoESkkMKyWszZfh7FlfVwsjTEd/M8YaQjgLOdCQxE2iiracTfheVch0mIwjRl/FALpRORg4MD3n//fRQUFKgjHo1TUlmPl3acx82yWjia6+OH1zxhqi8EAAi0+PAe2Pwfkm7PSHchkTIkasD8svspnYjeeust7N+/HwMGDMDkyZOxd+9e1NfXqyM2zpXVNODlb88jt7Qatia6+Ok1L1gY6siVGT+4+UF0Z3JKuAiREKVl3qpAZV0TDEXaGG7DffsQ0MlElJaWhsTERAwbNgzBwcGwtrbGkiVLkJKSoo4YOVFZ14ignYnIElfCwlCEn17zgk0bXfRjBzc/mjf52l1U1ze1+pwQTdNyW+bhqBntQ8AjtBGNHj0aW7ZsQWFhIcLDw7Fjxw54eHjAxcUFO3fu5GSks6rUNkjw6u4kpN8oh6meAD+95gUHc/02yzr00UM/U100ShjO593u4kgJUV5CruaMH2rR6UTU2NiIX375BdOnT8fbb78Nd3d37NixA8888wxWrVqFF198UZVxdik+HzDWE8BQRxs/vOqFwR0sn8nj8TDuXq3o9GVqJyKaTSJlSMz794kdmkLpkdUpKSnYtWsXfv75Z/D5fAQGBuKzzz7D0KFDZWWefvppeHh4qDTQriTS1sKXL45Gfml1h0moxfjB5vg5sQBnr1AiIpot81YFKuqaYCDSxmMa0j4EdCIReXh4YPLkyfjqq68QEBAAgUDQqoyjoyNeeOEFlQTIFYEWX6EkBAA+A83B5wFXiqtQWFbbZlsSIZqgZVqHh4MptLU0Z/SO0okoNzcX/fv377CMvr4+du3a1emguhtjPQFG9TNB2vUynM0pxfMedlyHREib/n1+mebclgGdaCOaOHEibt9u3ShbVlaGAQMGqCSo7kjWjU+3Z0RDSaUMiXmaNX6ohdKJKD8/HxKJpNX2+vp63Lx5UyVBdUfjhjQ3WJ/NKYGUpnsQDVLXKMHRS7ew8MdklNc2Ql+ohREa1D4EKHFrdujQIdm/jx07BmPjf2frSiQSxMTEwMHBQaXBdScu96Z73K1pxN+FFRjZj9vZzKR3a5JIEZ97GwfTCnHskhiV941xC3C11aj2IUCJRBQQEACgubs6KChI7jOBQAAHBwds3LhRpcF1JwItPh4f0AcnMotwOqeEEhHpcowxpBSU4ff0QhzOKERpVYPsMxtjHfg722C6iw2Ga8Bs+wcpnIik0uYlUR0dHXHhwgWYm5urLajuavwQc5zILMLZnFIsnjiI63BIL1JV34RXdl+QtQEBgKmeAE+NssZ0Z1u49zfl9CkdD6N0r1leXp464ugRxg5qTs5J1+6gpqEJekJOF8AkvUTzTIDmJKQr0MKUEVaY7myDsYPNIdCwW7D2KPRL2bJlCxYsWAAdHR1s2bKlw7JvvvmmSgLrjhzN9WFrooubZbU4n3sHE4dacB0S6eHqmyRY+GMyzufdgYFIG3vme2FUPxOuw1KaQkvFOjo6IikpCX369IGjo2P7B+PxkJubq9IAVe1Rl4p9mND9Gfg58TpeGeOIMP/hKj8+IS2aJFIs2ZOKo3+LoSPg44dXveDhoDnzx5ShUI3o/tsxujXr2LjBffFz4nVaFoSolVTKsPzXDBz9WwyhFh/bA927bRICaIVGlfMZ2Ac8HpBTXIVb5bVch0N6IMYYVh+8hOjUm9Di8xD54mjZxOvuSqEaUUhIiMIH3LRpU6eD6QlM9IQY1c8E6dfLcCanFM+703QPojqMMXx0JBN7zheAxwM+m+WCycMtuQ7rkSmUiFJTUxU6GI+nud2DXWn8YHOkt8w7o0REVGjziRzsONvcPPLxzFGY7mzDcUSqoVAiOnnypLrj6FHGDe6LL/66grNXSiGVMo0ev0G6j29OX8XnMTkAgHD/4T1qcjUNdFEDV3sT6Au1cKe6Af/cquD84XWkeyuuqMOWv3LwY0LzAyuW+zlh3pj2e6+7I4US0cyZM7F7924YGRlh5syZHZbdv3+/SgLrzlqe7nEisxinc0ooEZFOKatpwLZTudgdl4e6xuaZDUsmDuqRo/YVSkTGxsay9p/7J7uS9o0b3BcnMotxNqcUbzzR8/7HIepTXd+EXefy8PXpXNmjzUfbm2C531DZ46t6GoUGNPYk6h7Q2OJqSRUmbTwFoRYfaeGTaboHeai6Rgn2nC9A5MkruF3dPGF1qJUhlvs54T9DLXp0Z1Cnfx3FxcXIzs4GADg5OcHCgqYz3G/A/dM98u5gohNdH9K+/Sk38OmxbBSW1wFofjpMyJNOmDbSuld0dig9oLGiogIvv/wybG1tMWHCBEyYMAG2trZ46aWXUF5Oj11u0fx0j+ZJsLFZxRxHQzTZb8k3EPJLOgrL62BlpIOImSNxPGQCpjvb9IokBHQiEc2fPx/nz5/H4cOHUVZWhrKyMhw+fBhJSUl4/fXX1RFjt9Uy0Ox/l8SQ0KqNpA3Xblcj7OAlAMArYxwRu/wJzPa07zaz5lVF6Vuzw4cP49ixYxg7dqxsm5+fH7Zv344pU6aoNLjubuxgcxjqaKO4sh5J+Xc0bsFywq1GiRRL96ahukECT0czvPvUMI158mpXUzrt9unTp82eM2NjY5iamqokqJ5CpK0Fv8esAABHLt7iOBqiabbE5CDtehmMdLTx2SyXXpuEgE4kotWrVyMkJARisVi2TSwWY/ny5VizZo1Kg+sJnhplDQD44yLdnpF/JebdQeTJKwCAdTNHwraXPwtPoVszV1dXua7DnJwc2Nvbw97eHgBQUFAAkUiEkpISaid6wJiB5jDWFaC0qh6JeXd67DgQorjy2kYsi0qDlAHPuvXDtFE9Y77Yo1AoEbUsnK8OkZGR+OSTTyAWi+Hs7IwvvvgCnp6e7ZYvKyvDu+++i/379+POnTvo378/Nm/ejKlTp6otxkch1ObD7zFL/JJ0A0cuFlIi6uUYY3g3+iJultWifx89vDf9Ma5D0ggKJaLw8HC1nDwqKgohISHYtm0bvLy8sHnzZvj5+SE7O7vNcUkNDQ2YPHkyLCws8Ouvv8LW1hbXrl2DiYmJWuJTladG2eCXpBs4ekmM9/wf6/JHuUilDGGHLqG4oh5bZrtCR6DVpefvjhhjOHulFN+czsUwayOsmjpMJcf9LeUmDmfcgjafh89fcIWBiAa6AhxPet20aRPmz5+PefPmAQC2bduGI0eOYOfOnVi5cmWr8jt37sSdO3cQFxcHgUAAAN3iWWo+A/vARE+A0qoGJObdgc+grn0Cysbj2bIJk9+ezeuRc5VUKfnaXXxyLAsJuc1PxDiTUwqfgX3wxCMOSs0vrUb4va76ZZOHwMXO5FFD7TGU/tMskUjw6aefwtPTE1ZWVjAzM5N7KaqhoQHJycnw9fX9Nxg+H76+voiPj29zn0OHDsHb2xuLFy+GpaUlRowYgXXr1rX55NkW9fX1qKiokHt1NYEWH1Pu9Z79ntG1vWe/pxci8uRV2fvIk1dQXFHXpTF0F5m3KvDadxfwzFdxSMi9A6EWHyPvTVj+8EgmGiXSTh+7USLF0qjmrnovRzMsnDBQVWH3CEonorVr12LTpk2YNWsWysvLERISgpkzZ4LP5+O9995T+DilpaWQSCSwtJRfXc7S0lKuR+5+ubm5+PXXXyGRSPDHH39gzZo12LhxIz788MN2zxMREQFjY2PZy86OmzVcWnrPjl66haZH+B9aGZdulmP5r+kAgNfHD4CLnQlqGiT45Fh2l5y/u8gvrcbSvamYuuUMTmQWg88DZrnb4eTyJ/Dja14w0xfiSnEVfkq41ulzfH4iB+nUVd8upRPRTz/9hO3bt+Ptt9+GtrY2Zs+ejR07diAsLAwJCQnqiFFGKpXCwsIC33zzDdzc3DBr1iy8++672LZtW7v7hIaGory8XPa6fv26WmNsj/eAPjDTF+JuTSPic2+r/XwllfWY/30S6hqlmOjUF/83ZajsqSK/ptzAxRvcTMdpkkgRd7UU5TWNnJz/fsWVdQjdfxGTNp3CwbRCMAZMG2WN4yET8PGzo2BrogtjXQFCJg8BAHx2IgdlNQ0POWpr53NvIzK2uas+YuYo2PTyrvq2KJ2IxGIxRo4cCQAwMDCQzS+bNm0ajhw5ovBxzM3NoaWlhaKiIrntRUVFsLKyanMfa2trDBkyBFpa/za2Dhs2DGKxGA0Nbf8PIhKJYGRkJPfigrYWH1NG3BvcqObbs5ZnXd0qr8OAvvr4fLYrtPg8jLY3RYCLDRgD3j/8N7py4QWplOGPi7fgt/k05mw/D9/PTuFkNndz8G6W1eLpyDj8nFgAiZRholNfHHlzLLbOGY2BfQ3kyr7gYYehVoYor23E5hM5Sp2nuKIOb+5NBWPAc279ZDVjIk/pRNSvXz/cutX8Qxo4cCD+/PNPAMCFCxcgEokUPo5QKISbmxtiYmJk26RSKWJiYuDt7d3mPmPGjMGVK1dkj78GgMuXL8Pa2hpCoVDZr9Llpo28d3v2t/iR2hs6whhD2IG/kXztLgx1tLEj0B1GOgLZ5yv+OxQ6Aj4u5N/FHxfbvgVWdTynLpdgeuRZvPFTCq6WVIPHa66xzdt1AWsOXEJtQ/ttfOpQXFmHl3acx82yWjia62PfQm/smueJx2zaXmtLW4uPNdOaa5M/JFzDleJKhc5T1yjB6z8mo6iiHoMsDBBOXfXtUjoRPf3007LkERwcjDVr1mDw4MEIDAzEK6+8otSxQkJCsH37dnz33XfIzMzEokWLUF1dLetFCwwMRGhoqKz8okWLcOfOHSxduhSXL1/GkSNHsG7dOixevFjZr8EJT0czmBsIUVbTiLir6rk9+y4uH1FJ18HnAV/MdsWAB/66WxvryhpK1/2RibpG9SWBpPw7mPVNAoJ2JuLSzQroC7WwdNJgJK7yxVwfBwDNP+ynvjiDjBtlaovjfnerG/DyjkTklVbD1kQXP72m2EMJxwwyx+ThlpBIGT48kvnQ8owxrD5wCakFZTDWFWBHoDt11XdA6Suzfv162b9nzZoFe3t7xMfHY/DgwfD391fqWLNmzUJJSQnCwsIgFovh4uKCo0ePyhqwCwoKwOf/myvt7Oxw7NgxLFu2DKNGjYKtrS2WLl2KFStWKPs1ONFye/ZjQgGOZBRiwhDVPovq3JVSfHDvR7Lyv0Pb7W5+ffxARF24jptltWrpzv+7sByfHsvGyezmh0wKtfkIfLw/Fj0xEH0MmmvN701/DJOGWeCdfenILanGzC/jsHTSYCx6YqDaxllV1DUicGcisosqYWEowp75Xkq116yaOgyx2cWIzS7ByeziDteY2nkuH78m3wCfB2yd4woHc31VfIUei1Zo7GLxV29j9vYEGOloI2n1ZAi1O/7RlVTW493oi5AyBicrQzhZGWGolSEczfXlloq4drsaMyLPoaymEU+72mLT884druh3MO0mlu5Ng55QCyffeQKWRjqP/N0aJVKsjr6EqKTmDgEtPg/Pu9vhzUmDYG3c9g++rKYB70Zfkk0KHm1vgs9muaB/H9X+cGsamhC0MxEX8u/CTF+IqAWPY7ClodLH+ejIP9h+Jg8D++rj6Fvj21yu4/TlEszdlQgpA9ZMG45Xx/ashe7VoVOJKDs7G1988QUyM5v/+g4bNgzBwcFwcnJSeYCqxnUikkgZHo+IQUllPXbN9cDEoe3/VS2racAL3yQgS9y6TUKgxcPAvgb3kpMhDqTexOWiKjj3M0bU694PHT3NGMPMr+KQWlCGZ9364dPnnB/5ey2LSsOh9ELweMB0Zxu85TsEjgrUBBhjiE69ifCDf6Oyvgn6Qi2E+Q/H8+52Klketa5RgvnfJ+FMTikMdbTx8/zHO/1Ag4q6Rkz8JBa3qxsQ7j+81dM08kqrMWPrWVTUNeFZt3745NlRPXqJV1VRug7822+/YcSIEUhOToazszOcnZ2RkpKCESNG4LffflNHjD2KFp+Hqfd6zw530HtWWdeIoF0XkCWuRF9DEVY/NQyzPe0w2t4EBiJtNEoYssSVOJhWiA1Hs3G5qAoWhiJ8/bK7QlM4eDwewu41wP6a/Gjd+VIpw6r9F3EovRACLR52BLrj8xdcFUpCLbHMHN0P/3trHDwdzVDdIMGK3y5i+tZzOH255JF69xolUizZk4ozOaXQE2ph9zzPR3qqipGOACFPNnfnbz6Rg7vV//bWVtY1Yv73Saioa8JoexN89PQISkIKUrpGNHDgQLz44ot4//335baHh4fjxx9/xNWrV9vZUzNwXSMCmpeAeP7reBjqaCNptS9E2vKJo7ZBgqBdiUjMuwNTPQGiXvfGkPtuIxhjuHG3FtniSmQXVSJLXImSyjqsmjoMo/qZKBXLsqg0RKfehHt/U+xb6K30D4cxhrW//4Pdcfn32kNGY+rIzndRS6QMO87kYktMDqrv9aZ5OZrh/6Y4wa2/4iP3W471VlQafk8vhEibj13zPOAz8NGn10ikDE9tOYMscSWCvPtj7YwRkEgZFnyfhJisYlgZ6eBQ8BhYGD767W5voXQi0tPTQ0ZGBgYNkm/gzMnJgbOzM2pqalQaoKppQiKS3rs9K66sx7dB7pg07N/R5fVNEsz/PhmnL5fAUKSNnxd0/jZCEbfKa/GfT0+htlGCrXNclV6S4tNj2dh6b12dT59zxrNu/VQS1+2qenwZexU/JFxDQ1PzUIf/DLXA208Oabeb/X6lVfXYcDQLvyTdgECLh29edu/wNlhZcVdKMWfHeWjxeTi6dByiU2/iy9irEGnzsW+ht9J/EHo7pXvNnnjiCZw5c6ZVIjp79izGjRunssB6Mj6fh6kjrbE7Lh9HMm7JElGjRIrgPak4fbkEugIt7H7FQ+0PZ2zpzv/sxGVE/JEF32GWCs/Ojzx5RZaEPpjxmMqSEAD0MRDJGnq/+CsHvyTdwF9Zxfgrqxj+zjZY5jsYA/oaoLq+CZeLKmW1w2xx86vlcTx8HvD5C64qTUIA4HOvO//4P0WY/30S8m83/wHe8OwoSkKdoFCN6NChQ7J/FxYWIiwsDM8//zwef/xxAEBCQgL27duHtWvXYuHCheqLVgU0oUYENI+xeXZbPAxF2riw2hcCLT5CfknDwbRCCLX52DXXA2O6aJZ+bYMEkzbGorC8Dv7ONnh9/AA8ZmPU4W3arnN5WPv7PwCA0P8OxetqnsSZW1KFz07k4Pf0QgDNbW3Wxjq4cbe2zfI8HuDQRx9vPzlEbQuP5ZdWY/Jnp9Aoaf4JvT5hAEL/q5rlQnobhRLR/WN5OjwYj9fhTHhNoCmJSCpl8Fn/F8QVdfj6ZTfEZhfj58Tr0ObzsO0lN/gOt3z4QVTocEYhluxJlb0fYK6P6S42mO5s02pQZNSFAqz47SIA4M1Jg2VzsbrC34Xl2PjnZfx13yOa+hqK4GRpKOtBdLI0xGBLgy55qOX6/2Vh26mrmOjUFzuCPGgyayfROCIOvf/7P9h5Lg8megKU1TTKbiP8nblZOjQ2uxj7km7gRGYR6pv+nYIy0tYY051tMM3ZGol5d/BWVBoYA14b64h3nxrGSc9Q5q0KlNU0YoilgWyQJBckUobzubfh7mD20DFhpH2UiDiUUnAXM7+Mk73f8OwoPO/OzTIl96usa8Txf4pwKL0QZ3JKZYv+83gAD4CUAXO87PFRAHVPE9XoVAo/deoU/P39MWjQIAwaNAjTp0/HmTNnVB1bj+dqZyIba7N2+mMakYQAwFBHgJmj+2H3PE8krpqEDwJGwMPBFIw1J6GnXW3x4QxKQkR1lK4R/fjjj5g3bx5mzpyJMWPGAADOnTuH6Oho7N69G3PmzFFLoKqiSTUiACgsq0VxZX23WDb0ZlktrhRXYewgc2oLISqldCIaNmwYFixYgGXLlslt37RpE7Zv3y6b9qGpNC0REUI6cWuWm5vb5iz76dOnIy8vTyVBEUJ6F6UTkZ2dndxiZi1OnDjB2XrQhJDuTemBFm+//TbefPNNpKWlwcfHB0BzG9Hu3bvx+eefqzxAQkjP16nu++joaGzcuFFuGZDly5djxowZKg9Q1aiNiBDNo1SNqKmpCevWrcMrr7yCs2fPqismQkgvo1Qbkba2NjZs2ICmpiZ1xUMI6YWUbqyeNGkSTp06pY5YCCG9lNKN1f/973+xcuVKXLx4EW5ubtDXl1+Fb/r06SoLjhDSOyjdWN3RTHyafU8I6Qyla0T3P9yQEEJUgdYtIIRwrlOJKCYmBtOmTcPAgQMxcOBATJs2DSdOnFB1bISQXkLpRPTll19iypQpMDQ0xNKlS7F06VIYGRlh6tSpiIyMVEeMhJAeTunG6n79+mHlypVYsmSJ3PbIyEisW7cON2/eVGmAqkaN1YRoHqVrRGVlZZgyZUqr7U8++STKyzv/kD5CSO+ldCKaPn06oqOjW20/ePAgpk2bppKgCCG9i9Ld98OHD8dHH32E2NhYeHt7A2h+nNC5c+fw9ttvY8uWLbKyb775puoiJYT0WEq3ETk6Oip2YB4Pubm5nQpKnaiNiBDNo3SNiFZhJISoGg1oJIRwjhIRIYRzlIgIIZzTiEQUGRkJBwcH6OjowMvLC4mJiQrtt3fvXvB4PAQEBKg3QEKIWnGeiKKiohASEoLw8HCkpKTA2dkZfn5+KC4u7nC//Px8vPPOOxg3blwXRUoIUReFuu8zMjIUPuCoUaOUCsDLywseHh7YunUrgOZlRuzs7BAcHIyVK1e2uY9EIsH48ePxyiuv4MyZMygrK8OBAwcUOh913xOieRTqvndxcQGPx0N7OavlM2UXRmtoaEBycjJCQ0Nl2/h8Pnx9fREfH9/ufu+//z4sLCzw6quv4syZMx2eo76+HvX19bL3FRUVCsdHCOkaCiUidY0dKi0thUQigaWlpdx2S0tLZGVltbnP2bNn8e233yItLU2hc0RERGDt2rWPGiohRI0USkT9+/dXdxwKqaysxMsvv4zt27fD3NxcoX1CQ0MREhIie19RUUFPpCVEwyiUiA4dOqTwAZVZPN/c3BxaWlooKiqS215UVAQrK6tW5a9evYr8/Hz4+/vLtrUsXautrY3s7GwMHDhQbh+RSASRSKRwTISQrqdQIlK0e1zZNiKhUAg3NzfExMTIziGVShETE9NqvSMAGDp0KC5evCi3bfXq1aisrMTnn39ONR1CuimFEpE6F8wPCQlBUFAQ3N3d4enpic2bN6O6uhrz5s0DAAQGBsLW1hYRERHQ0dHBiBEj5PY3MTEBgFbbCSHdh9KTXlVt1qxZKCkpQVhYGMRiMVxcXHD06FFZA3ZBQUGHjzAihHR/Si8DAgDV1dU4deoUCgoK0NDQIPeZpq9BROOICNE8Siei1NRUTJ06FTU1NaiuroaZmRlKS0uhp6cHCwsLjVyD6H6UiAjRPErf8yxbtgz+/v64e/cudHV1kZCQgGvXrsHNzQ2ffvqpOmIkhPRwSieitLQ0vP322+Dz+dDS0kJ9fT3s7OywYcMGrFq1Sh0xEkJ6OKUTkUAgkDUeW1hYoKCgAABgbGyM69evqzY6QkivoHSvmaurKy5cuIDBgwdjwoQJCAsLQ2lpKX744QfqQieEdIrSNaJ169bB2toaAPDRRx/B1NQUixYtQklJCb7++muVB0gI6fk61X3fnVGvGSGaR+kaUV5eHnJyclptz8nJQX5+vipiIoT0Mkonorlz5yIuLq7V9vPnz2Pu3LmqiIkQ0ssonYhSU1MxZsyYVtsff/xxhdcIIoSQ+ymdiHg8HiorK1ttLy8vV2rmPSGEtFA6EY0fPx4RERFySUcikSAiIgJjx45VaXCEkN5B6XFEH3/8McaPHw8nJyfZEzTOnDmDiooK/PXXXyoPkBDS8yldIxo+fDgyMjLw/PPPo7i4GJWVlQgMDERWVhYNaCSEdAqNIyKEcK5TK46dOXMGL730Enx8fHDz5k0AwA8//ICzZ8+qNDhCSO+gdCL67bff4OfnB11dXaSkpMieGVZeXo5169apPEBCSM+ndCL68MMPsW3bNmzfvh0CgUC2fcyYMUhJSVFpcISQ3kHpRJSdnY3x48e32m5sbIyysjJVxEQI6WWUTkRWVla4cuVKq+1nz57FgAEDVBIUIaR3UToRzZ8/H0uXLsX58+fB4/FQWFiIn376Ce+88w4WLVqkjhgJIT2c0gMaV65cCalUikmTJqGmpgbjx4+HSCTCO++8g+DgYHXESAjp4To9jqihoQFXrlxBVVUVhg8fDgMDA9TW1kJXV1fVMaoUjSMiRPN0+smFQqEQw4cPh6enJwQCATZt2gRHR0dVxkYI6SUUTkT19fUIDQ2Fu7s7fHx8cODAAQDArl274OjoiM8++wzLli1TV5yEkB5M4VuzFStW4Ouvv4avry/i4uJQUlKCefPmISEhAatWrcJzzz0HLS0tdcf7yOjWjBDNo3Bj9b59+/D9999j+vTpuHTpEkaNGoWmpiakp6eDx+OpM0ZCSA+ncI1IKBQiLy8Ptra2AABdXV0kJiZi5MiRag1Q1ahGRIjmUbiNSCKRQCgUyt5ra2vDwMBALUERQnoXhW/NGGOYO3cuRCIRAKCurg4LFy6Evr6+XLn9+/erNkJCSI+ncCIKCgqSe//SSy+pPBhCSO9EC6MRQjjX6QGNhBCiKpSICCGc04hEFBkZCQcHB+jo6MDLywuJiYntlt2+fTvGjRsHU1NTmJqawtfXt8PyhBDNx3kiioqKQkhICMLDw5GSkgJnZ2f4+fmhuLi4zfKxsbGYPXs2Tp48ifj4eNjZ2eHJJ5+UrZ1NCOl+OG+s9vLygoeHB7Zu3QoAkEqlsLOzQ3BwMFauXPnQ/SUSCUxNTbF161YEBgY+tDw1VhOieTitETU0NCA5ORm+vr6ybXw+H76+voiPj1foGDU1NWhsbISZmVmbn9fX16OiokLuRQjRLJwmotLSUkgkElhaWsptt7S0hFgsVugYK1asgI2NjVwyu19ERASMjY1lLzs7u0eOmxCiWpy3ET2K9evXY+/evYiOjoaOjk6bZUJDQ1FeXi57Xb9+vYujJIQ8jNJLxaqSubk5tLS0UFRUJLe9qKgIVlZWHe776aefYv369Thx4gRGjRrVbjmRSCSblkII0Uyc1oiEQiHc3NwQExMj2yaVShETEwNvb+9299uwYQM++OADHD16FO7u7l0RKiFEjTitEQFASEgIgoKC4O7uDk9PT2zevBnV1dWYN28eACAwMBC2traIiIgAAHz88ccICwvDnj174ODgIGtLMjAwoNUACOmmOE9Es2bNQklJCcLCwiAWi+Hi4oKjR4/KGrALCgrA5/9bcfvqq6/Q0NCAZ599Vu444eHheO+997oydEKIinA+jqir0TgiQjRPt+41I4T0DJSICCGco0RECOEcJSJCCOcoERFCOEeJiBDCOUpEhBDOUSIihHCOEhEhhHOUiAghnKNERAjhHCUiQgjnKBERQjhHiYgQwjlKRIQQzlEiIoRwjhIRIYRzlIgIIZyjREQI4RwlIkII5ygREUI4R4mIEMI5SkSEEM5RIiKEcI4SESGEc5SICCGco0RECOEcJSJCCOcoERFCOEeJiBDCOUpEhBDOUSIihHCOEhEhhHOUiAghnKNERAjhnEYkosjISDg4OEBHRwdeXl5ITEzssPy+ffswdOhQ6OjoYOTIkfjjjz+6KFJCiDpwnoiioqIQEhKC8PBwpKSkwNnZGX5+figuLm6zfFxcHGbPno1XX30VqampCAgIQEBAAC5dutTFkRNCVIXHGGNcBuDl5QUPDw9s3boVACCVSmFnZ4fg4GCsXLmyVflZs2ahuroahw8flm17/PHH4eLigm3btj30fBUVFTA2NkZ5eTmMjIxU90UIIZ2mzeXJGxoakJycjNDQUNk2Pp8PX19fxMfHt7lPfHw8QkJC5Lb5+fnhwIEDbZavr69HfX297H15eTmA5oRECFE/Q0ND8Hi8DstwmohKS0shkUhgaWkpt93S0hJZWVlt7iMWi9ssLxaL2ywfERGBtWvXttpuZ2fXyagJIcpQ5O6D00TUFUJDQ+VqUFKpFHfu3IFAIIC9vT2uX79Ot2gqVFFRATs7O7quKtadr6uhoeFDy3CaiMzNzaGlpYWioiK57UVFRbCysmpzHysrK6XKi0QiiEQiuW0mJiayWzMjI6Nu9x+2O6Drqh499bpy2msmFArh5uaGmJgY2TapVIqYmBh4e3u3uY+3t7dceQA4fvx4u+UJIZqP81uzkJAQBAUFwd3dHZ6enti8eTOqq6sxb948AEBgYCBsbW0REREBAFi6dCkmTJiAjRs34qmnnsLevXuRlJSEb775hsuvQQh5BJwnolmzZqGkpARhYWEQi8VwcXHB0aNHZQ3SBQUF4PP/rbj5+Phgz549WL16NVatWoXBgwfjwIEDGDFihFLnFYlECA8Pb3XbRh4NXVf16OnXlfNxRIQQwvnIakIIoURECOEcJSJCCOcoERFCONcrE5Gyy46Q1k6fPg1/f3/Y2NiAx+O1muvHGENYWBisra2hq6sLX19f5OTkcBNsNxIREQEPDw8YGhrCwsICAQEByM7OlitTV1eHxYsXo0+fPjAwMMAzzzzTapBvd9PrEpGyy46QtlVXV8PZ2RmRkZFtfr5hwwZs2bIF27Ztw/nz56Gvrw8/Pz/U1dV1caTdy6lTp7B48WIkJCTg+PHjaGxsxJNPPonq6mpZmWXLluH333/Hvn37cOrUKRQWFmLmzJkcRq0CrJfx9PRkixcvlr2XSCTMxsaGRUREcBhV9waARUdHy95LpVJmZWXFPvnkE9m2srIyJhKJ2M8//8xBhN1XcXExA8BOnTrFGGu+jgKBgO3bt09WJjMzkwFg8fHxXIX5yHpVjahl2RFfX1/ZtoctO0KUl5eXB7FYLHedjY2N4eXlRddZSS3L1piZmQEAkpOT0djYKHdthw4dCnt7+259bXtVIupo2ZH2lhEhymu5lnSdH41UKsVbb72FMWPGyGYOiMViCIVCmJiYyJXt7teW8ykehJC2LV68GJcuXcLZs2e5DkXtelWNqDPLjhDltVxLus6dt2TJEhw+fBgnT55Ev379ZNutrKzQ0NCAsrIyufLd/dr2qkTUmWVHiPIcHR1hZWUld50rKipw/vx5us4PwRjDkiVLEB0djb/++guOjo5yn7u5uUEgEMhd2+zsbBQUFHTva8t1a3lX27t3LxOJRGz37t3sn3/+YQsWLGAmJiZMLBZzHVq3UllZyVJTU1lqaioDwDZt2sRSU1PZtWvXGGOMrV+/npmYmLCDBw+yjIwMNmPGDObo6Mhqa2s5jlyzLVq0iBkbG7PY2Fh269Yt2aumpkZWZuHChcze3p799ddfLCkpiXl7ezNvb28Oo350vS4RMcbYF198wezt7ZlQKGSenp4sISGB65C6nZMnTzIArV5BQUGMseYu/DVr1jBLS0smEonYpEmTWHZ2NrdBdwNtXVMAbNeuXbIytbW17I033mCmpqZMT0+PPf300+zWrVvcBa0CtAwIIYRzvaqNiBCimSgREUI4R4mIEMI5SkSEEM5RIiKEcI4SESGEc5SICCGco0REHtkTTzyBt956S+HysbGx4PF4reZLdaX33nsPLi4uHZbJz88Hj8dDWlpal8TUm9GAxl6i5SGWR44cQVFREUxNTeHs7IywsDCMGTPmkY59584dCAQCGBoaKlQ+NjYWEydOxN27d1stZ9FVqqqqUF9fjz59+gAA5s6di7KyMrklbyUSCUpKSmBubg5tbVqoQp3o6vYSzzzzDBoaGvDdd99hwIABKCoqQkxMDG7fvt3pYzY0NEAoFMoW7epODAwMYGBg0GEZLS2tbj2jvVvhdoYJ6Qp3795lAFhsbOxDy7366qvM3NycGRoasokTJ7K0tDTZ5+Hh4czZ2Zlt376dOTg4MB6PxxhjbMKECWzp0qWyct9//z1zc3NjBgYGzNLSks2ePZsVFRXJPm+Zp3b37t12YwHAvvzySzZlyhSmo6PDHB0d5ZZHZYyxjIwMNnHiRKajo8PMzMzY/PnzWWVlpdx5PDw8mJ6eHjM2NmY+Pj4sPz9f7ru0/BsPzO06efIky8vLYwBYamqq7JixsbHMw8ODCYVCZmVlxVasWMEaGxtln0+YMIEFBwez5cuXM1NTU2ZpacnCw8M7vO6kly0V21u1/PU/cOAA6uvr2y333HPPobi4GP/73/+QnJyM0aNHY9KkSbhz546szJUrV/Dbb79h//797badNDY24oMPPkB6ejoOHDiA/Px8zJ07V+m416xZg2eeeQbp6el48cUX8cILLyAzMxNA8+L9fn5+MDU1xYULF7Bv3z6cOHECS5YsAQA0NTUhICAAEyZMQEZGBuLj47FgwQLweLxW53nnnXfw/PPPY8qUKbh16xZu3boFHx+fVuVu3ryJqVOnwsPDA+np6fjqq6/w7bff4sMPP5Qr991330FfXx/nz5/Hhg0b8P777+P48eNKf/9ehetMSLrGr7/+ykxNTZmOjg7z8fFhoaGhLD09Xfb5mTNnmJGREaurq5Pbb+DAgezrr79mjDXXHAQCASsuLpYr82CN6EEXLlxgAGS1FUVrRAsXLpTb5uXlxRYtWsQYY+ybb75hpqamrKqqSvb5kSNHGJ/PZ2KxmN2+fbvDWuD9NSLGGAsKCmIzZsyQK/NgjWjVqlXMycmJSaVSWZnIyEhmYGDAJBKJ7FqMHTtW7jgeHh5sxYoV7X5XQjWiXuOZZ55BYWEhDh06hClTpiA2NhajR4/G7t27AQDp6emoqqqSPSur5ZWXl4erV6/KjtO/f3/07du3w3MlJyfD398f9vb2MDQ0xIQJEwAABQUFSsX84EJf3t7eshpRZmYmnJ2doa+vL/t8zJgxkEqlyM7OhpmZGebOnQs/Pz/4+/vj888/x61bt5Q6/4MyMzPh7e0tV6saM2YMqqqqcOPGDdm2UaNGye1nbW1Nj6t6CEpEvYiOjg4mT56MNWvWIC4uDnPnzkV4eDiA5l4ka2trpKWlyb2ys7OxfPly2THu/+G3peWWycjICD/99BMuXLiA6OhoAM2N211p165diI+Ph4+PD6KiojBkyBAkJCSo/bwCgUDuPY/Hg1QqVft5uzNKRL3Y8OHDZQ/uGz16NMRiMbS1tTFo0CC5l7m5ucLHzMrKwu3bt7F+/XqMGzcOQ4cO7XRt4MGkkZCQgGHDhgEAhg0bhvT0dLkHD547dw58Ph9OTk6yba6urggNDUVcXBxGjBiBPXv2tHkuoVAIiUTSYTzDhg1DfHw82H0jXs6dOwdDQ0O5daWJ8igR9QK3b9/Gf/7zH/z444/IyMhAXl4e9u3bhw0bNmDGjBkAAF9fX3h7eyMgIAB//vkn8vPzERcXh3fffRdJSUkKn8ve3h5CoRBffPEFcnNzcejQIXzwwQedinvfvn3YuXMnLl++jPDwcCQmJsoao1988UXo6OggKCgIly5dwsmTJxEcHIyXX34ZlpaWyMvLQ2hoKOLj43Ht2jX8+eefyMnJkSWyBzk4OCAjIwPZ2dkoLS1FY2NjqzJvvPEGrl+/juDgYGRlZeHgwYMIDw9HSEgI+Hz6KT0SrhupiPrV1dWxlStXstGjRzNjY2Omp6fHnJyc2OrVq+XWQq6oqGDBwcHMxsaGCQQCZmdnx1588UVWUFDAGGvdwNviwcbqPXv2MAcHByYSiZi3tzc7dOiQXKOvoo3VkZGRbPLkyUwkEjEHBwcWFRUlV6aj7nuxWMwCAgKYtbU1EwqFrH///iwsLEzWqPzgdykuLmaTJ09mBgYGj9x9/2DD/YwZM2RL6JK20chqopF4PB6io6MREBDAdSikC1B9khDCOUpEhBDO0VwzopGoxaB3oRoRIYRzlIgIIZyjREQI4RwlIkII5ygREUI4R4mIEMI5SkSEEM5RIiKEcI4SESGEc/8PUvoeWaqIbrsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recall = fr.spc(sim_data)\n",
    "\n",
    "g = fr.plot_spc(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crp = fr.lag_crp(sim_data)\n",
    "\n",
    "g = fr.plot_lag_crp(crp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network module of cymr contains code that implement the CMR model on a low-level, in terms of activations in two layers and the weights between them. This looks like the perfect level of abstraction to start modifying the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in term of structure of the model we have\n",
    "* layers = {'f', 'c'}\n",
    "* sublayers = e.x.{'location', 'category'}  -- the reason is to be able to set different parameters for different sublayers\n",
    "* segments = e.g. {item}\n",
    "* units = Each individual neuron\n",
    "\n",
    "Why are there both sublayers and segments? Why break apart so much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\n",
      "f_layer: 80 units\n",
      "    f_segment: 80 units\n",
      "\n",
      "c:\n",
      "c_layer: 80 units\n",
      "    c_segment: 80 units\n",
      "\n",
      "Context: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Features: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      " Here are the names we gave to each part of the network (used for index) and changing parameters and weights to only specific parts of the network\n",
      "['f_layer']\n",
      "['c_layer']\n",
      "{'f_layer': {'f_segment': 80}}\n",
      "{'c_layer': {'c_segment': 80}}\n",
      "\n",
      "Activation of the first unit: 0\n",
      "Pre-experimental connections between each neuron representing an event: (80, 80)\n",
      "Associations between items and context (80, 80) [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from cymr import network\n",
    "\n",
    "n_items = our_data.item_index.max() + 1\n",
    "\n",
    "f_segment = {'f_layer': {'f_segment': n_items}}\n",
    "c_segment = {'c_layer': {'c_segment': n_items}}\n",
    "\n",
    "net = network.Network(f_segment, c_segment)\n",
    "\n",
    "print(net)\n",
    "print(\"Context:\", net.c)\n",
    "print(\"Features:\", net.f)\n",
    "print(\"\\n Here are the names we gave to each part of the network (used for index) and changing parameters and weights to only specific parts of the network\")\n",
    "print(net.f_sublayers)\n",
    "print(net.c_sublayers)\n",
    "print(net.f_segment)\n",
    "print(net.c_segment)\n",
    "print(\"\\nActivation of the first unit:\", net.get_unit('f', 'f_layer', 'f_segment', 0))\n",
    "print(\"Pre-experimental connections between each neuron representing an event:\", net.w_ff_pre.shape)\n",
    "print(\"Associations between items and context\", net.w_cf_exp.shape,net.w_fc_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we have 24 items we want to represent, and we want to associate each of them with a category. Then  we can create these weight as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\n",
      "task: 24 units\n",
      "    item: 24 units\n",
      "\n",
      "c:\n",
      "loc: 24 units\n",
      "    item: 24 units\n",
      "cat: 3 units\n",
      "    item: 3 units\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) Create the network\n",
    "from cymr import network\n",
    "\n",
    "f_segment = {'task': {'item': 24}}\n",
    "c_segment = {\n",
    "    'loc': {'item': 24},\n",
    "    'cat': {'item': 3},\n",
    "}\n",
    "\n",
    "net = network.Network(f_segment, c_segment)\n",
    "\n",
    "print(net)\n",
    "\n",
    "# (2) We can set the weights in the network manually \n",
    "import numpy as np\n",
    "\n",
    "cat = np.zeros((24, 3))\n",
    "cat[:8, 0] = 1\n",
    "cat[8:16, 1] = 1\n",
    "cat[16:, 2] = 1\n",
    "\n",
    "# and can save these patterns in a dictionary\n",
    "patterns = {\n",
    "    'vector': {\n",
    "        'loc': np.eye(24),\n",
    "        'cat': cat,\n",
    "    },\n",
    "}\n",
    "# cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed:\n",
      "\n",
      "\n",
      "free:\n",
      "\n",
      "\n",
      "dependent:\n",
      "\n",
      "\n",
      "dynamic:\n",
      "\n",
      "\n",
      "sublayers:\n",
      "f: ['task']\n",
      "c: ['loc', 'cat']\n",
      "\n",
      "weights:\n",
      "fc: {(('task', 'item'), ('loc', 'item')): 'loc', (('task', 'item'), ('cat', 'item')): 'cat'}\n",
      "cf: {(('task', 'item'), ('loc', 'item')): 'loc', (('task', 'item'), ('cat', 'item')): 'cat'}\n",
      "\n",
      "sublayer_param:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (2) Define the pre-experimental weights of the network\n",
    "from cymr import cmr\n",
    "\n",
    "param_def = cmr.CMRParameters()\n",
    "param_def.set_sublayers(f=['task'], c=['loc', 'cat'])\n",
    "weights = {\n",
    "    (('task', 'item'), ('loc', 'item')): 'loc',\n",
    "    (('task', 'item'), ('cat', 'item')): 'cat',\n",
    "}\n",
    "param_def.set_weights('fc', weights)\n",
    "param_def.set_weights('cf', weights)\n",
    "\n",
    "print(param_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
