{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can use a neural network with one input and one output node for linear regression problem.\n",
    "\n",
    "$y = mx + b$ \n",
    "\n",
    "$y = (weight)x + bias$ \n",
    "\n",
    "Minimizing residuals $\\iff$ Minimizing SSE for Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of statistical regression that neural networks can implment based on the **activation function** you choose\n",
    "\n",
    "Activations:\n",
    "\n",
    "* Linear --> Linear regression\n",
    "* Sigmoid --> Sigmoid regression\n",
    "* tanh --> tanh regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doctor strange punched through super high dimensional space \n",
    " * Space we are trying to have our optimizer navigate our current weights to using `gradient descent`\n",
    "\n",
    "Big Idea: \n",
    "\n",
    "Machine learning reseach -- normally we do not *reason* but *rationalize* why this is occuring\n",
    "Networks work a lot better when using rectified linear function as opposed to sigmoid function\n",
    "* Sigmoid function gets stucked in error space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum - each time you move the weight vector, some part of the **$\\Delta$ weight** is carried over to next move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimizing SSE\n",
    "*How do you find the direction of the gradient on the SSE surface* $\\iff$ How to find directional derivative of SSE with respect to each weight in network$\n",
    "\n",
    "$SSE = \\sum^{}_{Patterns} \\sum^{}_{Squared Error}$\n",
    "\n",
    "$ -\\frac{d(SSE)}{d(w_{ij})}$ = $ \\frac{d}{dw_{ij}} \\sum^{}_{Patterns} \\sum^{}_{Squared Error} $\n",
    "\n",
    "Partial derivative of sum = Sum of partial derivative\n",
    "\n",
    "*Chain Rule* - $\\frac{Change in SSE}{Change in Ouput} * \\frac{Change in Output}{Change in weight}$ \n",
    "\n",
    "Get rid of Sigma (change in output $o_{ik}$ with k not requal to j, with respect to weight for all output units\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance of Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once accuracy on validation set starts decreasing, then that is a sign that the model is learning noise that does not generalize to other training patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3730d5d1c31a0f0507cb21031ee0b4e9aa5b7079f3ceca5ddb3f252bb92fdf07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
