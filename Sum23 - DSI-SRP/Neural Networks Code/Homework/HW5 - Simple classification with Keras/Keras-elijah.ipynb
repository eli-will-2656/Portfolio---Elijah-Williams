{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Keras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow is a python library containing modules such as `models` and `layers`, that can help organize and train neural networks.\n",
    "\n",
    "* Model = Groups together multiple layers into one network\n",
    "   * `compile()` - \n",
    "   * `fit()` - train neural network on training patterns\n",
    "   * `predict()` - generate predictions for given inputs into neural network\n",
    "   \n",
    "\n",
    "* Layers = Groups together multiple neurons into single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequential Model** = Feedforward network\n",
    "\n",
    "Graph the contains directed edges away from input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Creating a sequential model (activations of one layer determine by activation of pervious layer)\n",
    "network  = models.Sequential()\n",
    "\n",
    "# Adding a layer\n",
    "nin = 2\n",
    "nout = 1\n",
    "network.add(layers.Dense(nout, # number of output nodes\n",
    "                        activation= 'linear',\n",
    "                        input_shape=(nin,)\n",
    "                        ))\n",
    "\n",
    "print(network.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the input nodes are treated as parameters to the `network` function, and our input and first layer forms complete bipartite graph, in which there is a directed edge from each of the input neurons to output neurons\n",
    "\n",
    "`layers.Dense = activation_function(dot(inputs, kernel (weights)) + bias)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer name : dense_4 | input shape : (None, 2) | output shape : (None, 1)\n",
      "{'name': 'dense_4', 'trainable': True, 'batch_input_shape': (None, 2), 'dtype': 'float32', 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n"
     ]
    }
   ],
   "source": [
    "# For each layer in our network, we print out its name, input shape, output shape, and configuration\n",
    "for layer in network.layers:\n",
    "    print(f'layer name : {layer.name} | input shape : {layer.input.shape} | output shape : {layer.output.shape}')\n",
    "    print(layer.get_config())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notices that the **number of parameters for a layer** =  **size(kernel) = size(weight matrix (including bias vector))** for the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 3)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "************************************************\n",
      "\n",
      "layer name : dense_5 | input shape : (None, 4) | output shape : (None, 3)\n",
      "************************************************\n",
      "\n",
      "{'name': 'dense_5', 'trainable': True, 'batch_input_shape': (None, 4), 'dtype': 'float32', 'units': 3, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "\n",
    "nin  = 4\n",
    "nout = 3\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(nout, \n",
    "                         activation='sigmoid', \n",
    "                         input_shape=(nin,)))\n",
    "\n",
    "print(network.summary())\n",
    "print('************************************************\\n')\n",
    "\n",
    "for layer in network.layers:\n",
    "    print('layer name : {} | input shape : {} | output shape : {}'.format(layer.name, layer.input.shape, layer.output.shape))\n",
    "print('************************************************\\n')\n",
    "\n",
    "for layer in network.layers:\n",
    "    print(layer.get_config())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a hidden layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 5)                 25        \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43\n",
      "Trainable params: 43\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = models.Sequential()\n",
    "\n",
    "nin  = 4\n",
    "nhid = 5\n",
    "nout = 3\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(nhid, \n",
    "                         activation='sigmoid', \n",
    "                         input_shape=(nin,)))\n",
    "network.add(layers.Dense(nout, \n",
    "                         activation='sigmoid'))\n",
    "\n",
    "print(network.summary())\n",
    "print('************************************************\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer name : dense_8 | input shape : (None, 4) | output shape : (None, 5)\n",
      "layer name : dense_9 | input shape : (None, 5) | output shape : (None, 3)\n",
      "************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer in network.layers:\n",
    "    print('layer name : {} | input shape : {} | output shape : {}'.format(layer.name, layer.input.shape, layer.output.shape))\n",
    "print('************************************************\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you are done building you neural network, you compile it with a given:\n",
    "* optimizer - how neural network is turned into function of efficient matrix calculations (turning into single matrix)\n",
    "* loss function - way for model to calculate error from desired outputs (SSE, Cross-entropy) = \"What are you optmizing?\"\n",
    "* metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "elijah_model = models.Sequential()\n",
    "nin = 2\n",
    "nout = 1\n",
    "\n",
    "# sigmoid activation - 0 when net is low, 1 when net is high\n",
    "elijah_model.add(\n",
    "layers.Dense(\n",
    "    nout,\n",
    "    activation='sigmoid',\n",
    "    input_shape=(nin,)\n",
    "    )\n",
    ")\n",
    "\n",
    "elijah_model.compile (\n",
    "    # add a optimizer (how to minimize error)\n",
    "    optimizer=\"sgd\",\n",
    "    # add a loss function (how error is calculated)\n",
    "    loss=\"mean_squared_error\",\n",
    "    # add metrics\n",
    "    metrics=['accuracy','mse']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training network\n",
    "Here we call `fit()` method, so that it initializes it's weights to minimize error as best we can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\NSC3270\\Homework\\HW5 - Simple classification with Keras\\Keras-elijah.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/NSC3270/Homework/HW5%20-%20Simple%20classification%20with%20Keras/Keras-elijah.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/NSC3270/Homework/HW5%20-%20Simple%20classification%20with%20Keras/Keras-elijah.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m training_pats \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate( (     np\u001b[39m.\u001b[39mones((\u001b[39m500\u001b[39m,\u001b[39m2\u001b[39m)) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mrandn((\u001b[39m500\u001b[39;49m,\u001b[39m2\u001b[39;49m))  , \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/NSC3270/Homework/HW5%20-%20Simple%20classification%20with%20Keras/Keras-elijah.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                       np\u001b[39m.\u001b[39mzeros((\u001b[39m500\u001b[39m,\u001b[39m2\u001b[39m)) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandn((\u001b[39m500\u001b[39m,\u001b[39m2\u001b[39m)) )  , axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/NSC3270/Homework/HW5%20-%20Simple%20classification%20with%20Keras/Keras-elijah.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m training_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/NSC3270/Homework/HW5%20-%20Simple%20classification%20with%20Keras/Keras-elijah.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         np\u001b[39m.\u001b[39mconcatenate((np\u001b[39m.\u001b[39mzeros(\u001b[39m500\u001b[39m), np\u001b[39m.\u001b[39mones(\u001b[39m500\u001b[39m)), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/NSC3270/Homework/HW5%20-%20Simple%20classification%20with%20Keras/Keras-elijah.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         (\u001b[39m1000\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/NSC3270/Homework/HW5%20-%20Simple%20classification%20with%20Keras/Keras-elijah.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m elijah_model\u001b[39m.\u001b[39mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/NSC3270/Homework/HW5%20-%20Simple%20classification%20with%20Keras/Keras-elijah.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     training_pats,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/NSC3270/Homework/HW5%20-%20Simple%20classification%20with%20Keras/Keras-elijah.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     training_labels,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/NSC3270/Homework/HW5%20-%20Simple%20classification%20with%20Keras/Keras-elijah.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/NSC3270/Homework/HW5%20-%20Simple%20classification%20with%20Keras/Keras-elijah.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     )\n",
      "File \u001b[1;32mmtrand.pyx:1246\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randn\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mmtrand.pyx:1403\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.standard_normal\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_common.pyx:630\u001b[0m, in \u001b[0;36mnumpy.random._common.cont\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "training_pats = np.concatenate( (     np.ones((500,2)) + np.random.randn((500,2))  , \n",
    "                                      np.zeros((500,2)) + np.random.randn((500,2)) )  , axis=0)\n",
    "training_labels = np.reshape(\n",
    "        np.concatenate((np.zeros(500), np.ones(500)), axis=0),\n",
    "        (1000, 1))\n",
    "\n",
    "elijah_model.fit(\n",
    "    training_pats,\n",
    "    training_labels,\n",
    "    validation_split=.1, \n",
    "    epochs=20, \n",
    "    batch_size=128\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3730d5d1c31a0f0507cb21031ee0b4e9aa5b7079f3ceca5ddb3f252bb92fdf07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
